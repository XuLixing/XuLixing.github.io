<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Introduction to My Blog</title>
    <url>/2021/04/13/blog-inro/</url>
    <content><![CDATA[<p>This is my blog, built at March, 2021, supported by Github &amp; Hexo &amp; NexT Theme.</p>
<p>Accumulation does matter.</p>
<p>This blog would serve as window, where I could share my my points, output fantastic ideas and trace any change inside my mind.</p>
<p>For Now, I would focus more on producing notes and posts from my leanrning, as many as possible.</p>
<p>I hope that what i will write or i have wrriten would make a difference to the world.</p>
]]></content>
      <tags>
        <tag>Introduction</tag>
      </tags>
  </entry>
  <entry>
    <title>5. Memory Hierachy</title>
    <url>/2021/11/07/computer-architecture/5.memory-hierachy/</url>
    <content><![CDATA[<h1 id="5-1-Memory-Hierachiy-Overview"><a href="#5-1-Memory-Hierachiy-Overview" class="headerlink" title="5.1  Memory Hierachiy Overview"></a>5.1  Memory Hierachiy Overview</h1><h2 id="5-1-1-Memory-development"><a href="#5-1-1-Memory-development" class="headerlink" title="5.1.1 Memory development"></a>5.1.1 Memory development</h2><p>Memory的性能发展并没有跟上CPU的性能，在计算机运算（CPU和Memory协同）内存的访问时间即数据的搬运时间过长，制约了计算性能。处理器的性能的发展速度远超于内存（如DRAM）的发展速度，这里有电路设计优化的因素，也有工艺的因素。处理器如果需要快速的处理数据，无论是指令还是数据，存储系统都应该能够快速供给。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/1.png" alt="Memory Wall"></p>
<p>一个很简单解决思路是：让memory系统层次化。靠近CPU的数据（即准备要用到的数据）使用访问速度快的存储类型如SRAM，稍远的则采用访问速度慢但容量大的DRAM。进一步，我们把计算机最常用的指令(如load，strore)和数据预存在更小的memory中，我们称其为cache 或高速缓存。存储在cache中的数据，可以被CPU快速访问。</p>
<p>Note：cache中可以存储指令和数据，在之后的介绍中仅描述为data。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/2.png" alt="Memory Hierachy"></p>
<h2 id="5-1-2-Cache-访问逻辑"><a href="#5-1-2-Cache-访问逻辑" class="headerlink" title="5.1.2 Cache 访问逻辑"></a>5.1.2 Cache 访问逻辑</h2><p>当CPU需要访问内存地址，即读对应的数据时，高速缓存的操作如下：</p>
<ol>
<li>先检查cache中有无匹配的地址: cache line/entry </li>
<li>假如内存的地址可以在cache里找到，cache只需要将数据传回，这个过程为Cache Hit</li>
<li>假如内存地址不在cache中找到，cache就会分配一个cache line给这个地址，处理器需要访问main memory，处理器往往需要停下来（Microprocessor stall）等到data从main memory中传回，这个过程为Cache Miss。以此类推，当Memory hierarchy更复杂时，也会有Main Memory Hit/ Miss。</li>
</ol>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/3.png" alt="cache访问逻辑"></p>
<p>当CPU往内存写数据时，即写入对应数据时，高速缓存的操作如下：</p>
<ol>
<li>会先检查cache中有无这个地址，有则写入数据到对应的cache位置；</li>
<li>如果没有，则按照某种（policy）处理，这点在后边章节5.3.3细述。</li>
</ol>
<h1 id="5-2-Memory-System-Performance-Analysis"><a href="#5-2-Memory-System-Performance-Analysis" class="headerlink" title="5.2 Memory System Performance Analysis"></a>5.2 Memory System Performance Analysis</h1><p>Miss Rate/ Hit Rate：重要的指标来衡量存储层次的性能。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/4.png" alt="Hit&amp;Miss rate"></p>
<p>Average memory access time AMAT:平均内存访问时间：</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/5.png" alt="Average memory access time AMAT"></p>
<h1 id="5-3-Cache"><a href="#5-3-Cache" class="headerlink" title="5.3 Cache"></a>5.3 Cache</h1><p>紧接着根据以下三个问题来讨论cache的设计。</p>
<p>（1）具体什么样的data需要存放在cache？</p>
<p>（2）data如何被处理器发现？</p>
<p>（3）cache中的什么数据被新的数据取代，当cache写满时。</p>
<h2 id="5-3-1-具体什么样的data需要存放在cache？"><a href="#5-3-1-具体什么样的data需要存放在cache？" class="headerlink" title="5.3.1 具体什么样的data需要存放在cache？"></a>5.3.1 具体什么样的data需要存放在cache？</h2><p>Cache是无法聪明到可以预测接下来处理器会用到什么数据，所以cache只能去猜什么样的数据可能被需要，<strong>基于过去memory access pattern</strong>。特别地，cache使用的时间局域性（Temporal locality）和空间局域性（Spatial locality）以获得非常的低的miss rate。</p>
<h3 id="5-3-1-1-访存的局域特性"><a href="#5-3-1-1-访存的局域特性" class="headerlink" title="5.3.1.1 访存的局域特性"></a>5.3.1.1 访存的局域特性</h3><p>大多数程序并不会在所有时刻访问整个存储空间，访存位置出现局域性特点。</p>
<p><strong>A. 时间局域性 Temporal locality</strong> 指的是处理器很可能马上访问某一个数据，如果某一个数据被访问。因此当处理器从Main memory搬运特定数据到cache中，这个特定数据紧接着常用的数据也被搬运到cache中。</p>
<p>eg. 进入一个for循环，for内的数据比如i++，数据1和指令”+“会被反复用到。</p>
<p><strong>B. 空间局域性 Spatial locality</strong> 指的是处理器访问一个main memory的数据之后，那个特定数据所在memory位置的周围的数据很有可能被访问。因而附近的数据也会被一起搬运进入cache中。</p>
<p>eg. 比如矩阵乘法，比如图像边缘提取，附近的element会被一起计算。 </p>
<h3 id="5-3-1-2-cache存储的基本单位：Block-Cache-line-Cache-entry"><a href="#5-3-1-2-cache存储的基本单位：Block-Cache-line-Cache-entry" class="headerlink" title="5.3.1.2 cache存储的基本单位：Block/Cache line/Cache entry"></a>5.3.1.2 cache存储的基本单位：Block/Cache line/Cache entry</h3><p>通常处理器只会需求一个指令（对于MIPS系统则是一个word，32bit），但是cache的一个存储单位Block可以容纳不止一个word。因而当cache取特定指令（word）时候，往往连带其他指令（word）一起取回，存在block中。</p>
<p>总结以下，cache通常有以下几个parameter去描述：</p>
<ol>
<li>容量Capacity C：cache中能存有words的数量。</li>
<li>set（entry）S：set的数量。</li>
<li>block的大小 b：block size，number of words it contains</li>
<li>block的数量 B：number of blocks</li>
<li>关联度 N：degree of associativity</li>
</ol>
<h2 id="5-3-2-Data如何被处理器发现？"><a href="#5-3-2-Data如何被处理器发现？" class="headerlink" title="5.3.2 Data如何被处理器发现？"></a>5.3.2 Data如何被处理器发现？</h2><p>简单介绍一个cache的物理结构：一个cache分布在S个set中，（set可以粗略理解为行row），每一个set中容纳了一个或者多个block，每一个block容纳word的数量则取决于block size，b。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/6.png" alt="Mapping"></p>
<p>需要注意的是，当我们需要从Main memory取数据放入cache中时，cache的地址与Main memory地址有一种对应的位置，称为mapping。</p>
<p>特别地，每一个Main memory的地址仅仅对应到一个cache set地址。当一个cache set中含有多个block，则Main memory中数据可以进入指定set中的任意一个block中。按照一个cache set中的block 的数量，可以把cache分为几类。</p>
<ol>
<li>Directed mapped cache:<br>每一个cache set只含有一个block，因此cache set的数量S=B。一个Main memory的地址对应到唯一的cache set中唯一的block中，没有其他block可进入。</li>
<li>N-way set associative cache:<br>每一个cache set含有N个block，因此cache set的数量 S=B/N。一个Main memory 的地址对应到唯一的cache set，但是data可以进入特定set N block中任意一个block中。</li>
<li>A fully associative cache:<br>只有一个set，S=1，N=B。数据可以进入一个set，B个block中的任意一个。</li>
</ol>
<p>下面按照MIPS的memory系统为例子介绍cache三种架构。MIPS是一个32位系统，地址32位且byte-addressable，每一个地址包含4个byte。下面我们以cache capacity = C =8 words 作为例子讨论。</p>
<h3 id="5-3-2-1-Direct-mapped-cache"><a href="#5-3-2-1-Direct-mapped-cache" class="headerlink" title="5.3.2.1 Direct mapped cache"></a>5.3.2.1 Direct mapped cache</h3><p>首先需要知道direct mapped cache的mapping，左边为main memory 的地址，右边为cache的结构。右边cache的结构为direct mapped cache，一行有一个block，一个block存一个word。左边Main memory每个address存一个byte，0x0-0x3位置存在Set0，0x4-0x7位置存在Set1，以此类推，直到0x20-0x23位置又存回Set0中，以此循环。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/7.png" alt="Mapping"></p>
<p>回到5.3.2节我们需要讨论的东西，如何从cache address找到Main memory的数据？这就需要知道Main memory的地址如何对应到cache，这与memory的地址相关。对于地址如0xFFFFFFE4，32位可以分为byte offset，index（set bit），tag bit等。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/8.png" alt="Memory Adress 组成"></p>
<p>Byte offset：两位表示选中cache line的4个byte中选1个byte；</p>
<p>Index/Set offset：表示需要选中cache set的地址/行数；</p>
<p>Tag bit：剩下的bits在offset和set bit数量被决定，tag bit用来区分memory&amp;cache的mapping。</p>
<p>tag bit的内容也存在cache中。cache中可能还存有V（valid）和D（Dirty）bit。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/9.png" alt="Cache line 组成"></p>
<p>上图则表明了mapping的细节，set bit选 cache set，tag bit比较，valid有效时，生成hit信号。</p>
<p>Valid bit：cache set用这个valid bit表明这个set保存的data是否是有效的数据。valid=1，内容是有效的；valid=0，内容是无效的；当两个最近需要访问的地址map到了同一个cache block，这就是一个conflict发生了，所以最近的地址会驱逐前一个地址。</p>
<p>总结这种directed mapping的方式：</p>
<p>优点：设计简单，造价低，搜索速度快（几乎不用搜索） </p>
<p>缺点：因为序号index的共享度高，hit rate低。</p>
<h3 id="5-3-2-2-Multi-way-set-associative-cache"><a href="#5-3-2-2-Multi-way-set-associative-cache" class="headerlink" title="5.3.2.2 Multi-way set associative cache"></a>5.3.2.2 Multi-way set associative cache</h3><p>N-way set associative cache通过在一个set中提供N blocks，可以显著减少数据的conflict。N就被称为degree of associativity 相关度。C=8 word，N=2 way，S=4 set。对比上面的cache结构，log2(4)=2，则需要2个而不是3个select bit。tag bit则是28 bit而不是27bit。mapping的外围电路则是用到两个比较器，两个valid信号。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/10.png" alt="Multi-way set associative cache"></p>
<p>这类Set associative cache generlly有更低的miss rate相比于direct mapped cache（在相同的capacity的基础上）因为他们有更少的conflicts。但是这类set associativity cache通常会更慢和某种程度上更贵因为需要在output stage建立multiplexer和额外的比较器。</p>
<p>还值得注意的是：Multi-way的cache结构中，每一个cache set会有多组tag和valid bit。因此当N数量增加时，cache占用的总存储面积是上升的（容量C一定情况下）。</p>
<p>还有一个重要的事情是，在N-way已经满了而要写入数据时，哪一个数据需要被取代。这点将在5.3.3节讨论。Set associative cache常常被用作商业用途。</p>
<h3 id="5-3-2-3-Fully-associative-cache"><a href="#5-3-2-3-Fully-associative-cache" class="headerlink" title="5.3.2.3 Fully associative cache"></a>5.3.2.3 Fully associative cache</h3><p>一个Fully associative cache涵盖一个single set，但是有B个ways，B是block数量。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/11.png" alt="Fully associative cache"></p>
<p>这种cache类型相比于上述两种类型，有着最小的conflict misses rate（当cache容量一定时）缺点也明显，他需要极其多的硬件资源，such as tag bit comparators and mulitiplexers。</p>
<h3 id="5-3-2-4-Consideration-Block-size，b"><a href="#5-3-2-4-Consideration-Block-size，b" class="headerlink" title="5.3.2.4 Consideration: Block size，b"></a>5.3.2.4 Consideration: Block size，b</h3><p>我们再考虑一个重要的参数，block size，一个block中可以容纳超过一个word，超过一个word长度，因此可以充分利用到时间局域性和空间局域性。在一个word被取入cache block时，相邻的word也被一起存入cache block。<strong>但对于miss rate来说，增加block size的方法并不一定能够一定减少miss rate。</strong>这是因为当cache 容量一定的情况下，增加block size意味着block set的数量更小，单个block set map到的memory地址数量更多，miss rate还可能增加。</p>
<p>额外的，这增加了一个cache block的写入时间，因为写入的word数量增加。因此一旦发生了miss，从main memory进行搬运时，miss penalty会非常大。若想要降低miss penality则需要进一步层次化memory，如使用多级缓存结构。</p>
<p>结构上需要添加，block offset进行数据的选择。</p>
<p>现阶段，商用的cache架构还是会采用大的block size。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/12.png" alt="Block size 的影响"></p>
<p>总结一下三种cache type：</p>
<p>Increasing the associativity, N, usually reduces the miss rate caused by conflicts. But higher associativity requires more tag comparators. Increasing the block size, b, takes advantage of spatial locality to reduce the miss rate. However, it decreases the number of sets in a fixed sized cache and therefore could lead to more conflicts. It also increases the miss penalty.</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/13.png" alt="三种cache类型的总结"></p>
<h2 id="5-3-3-Cache中的什么数据被新的数据取代"><a href="#5-3-3-Cache中的什么数据被新的数据取代" class="headerlink" title="5.3.3 Cache中的什么数据被新的数据取代?"></a>5.3.3 Cache中的什么数据被新的数据取代?</h2><p>首先引入一个概念：高速缓存的缺失，它指的是所访问的内存地址还没有预取到cache中。当发生缺失时候，则需要讲内存的数据取出放入cache中，当cache中有数据时，就需要进行替换。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Memory%20Hierachy/14.png" alt="三种cache类型的总结"></p>
<p>数据的替换策略与映射方式相关：</p>
<ol>
<li>对于direct mapped cache每一个地址对应到唯一block set，所以这个block中内容就是victim；</li>
<li>对于N-way set associative cache，如果set is full，则需要按照一定的规则来驱逐（evit）特定的block，被替换的block成为victim。</li>
<li>对于full associative cache，如果整个set都满了，就需要替换。</li>
</ol>
<p>以N-way set associative cache为例，替换策略有：</p>
<ol>
<li>轮换策略：先入先出，将一组各路乱换，算法简单，全局利用效率低。</li>
<li>LRU（Least recentyly used）policy：对各路进行位置进行排序，最常用的放到队列底；最不常用到的放到队列顶被替换。</li>
<li>随机策略：最容易实现。</li>
</ol>
<p>数据的替换策略与映射方式相关：</p>
<ol>
<li>对于direct mapped cache每一个地址对应到唯一block set，所以这个block中内容就是victim；</li>
<li>对于N-way set associative cache，如果set is full，则需要按照一定的规则来驱逐（evit）特定的block，被替换的block成为victim。</li>
<li>对于full associative cache，如果整个set都满了，就需要替换。</li>
</ol>
<p>以N-way set associative cache为例，替换策略有：</p>
<ol>
<li>轮换策略：先入先出，将一组各路乱换，算法简单，全局利用效率低。</li>
<li>LRU（Least recentyly used）policy：对各路进行位置进行排序，最常用的放到队列底；最不常用到的放到队列顶被替换。</li>
<li>随机策略：最容易实现。</li>
</ol>
<h2 id="5-3-4-Write-Policy"><a href="#5-3-4-Write-Policy" class="headerlink" title="5.3.4 Write Policy"></a>5.3.4 Write Policy</h2>]]></content>
      <categories>
        <category>Computer architecture</category>
      </categories>
      <tags>
        <tag>Computer architecture</tag>
      </tags>
  </entry>
  <entry>
    <title>Von Neumann Model &amp; ISA</title>
    <url>/2021/06/07/computer-architecture/von-neumann-model-isa/</url>
    <content><![CDATA[<p>Reference：</p>
<ol>
<li><em>Digital Design and Computer Architecture,</em> by David Harris, Sarah Harris-chapter6 </li>
<li><em>Introduction to Computing Systems</em>, by Yale N.Patt, Sanjay J. Patel, chapter4-5</li>
</ol>
<h3 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview:"></a>1. Overview:</h3><p>本节主要介绍经典的架构和指令集的概念。所有的程序最后都会通过编译器编译成一条条指令执行。指令就像是特定的单词用于告诉计算机需要做什么，指令集就像是计算机能听懂的词汇类型。需要主要的是：就算是基于同样的架构和同样的指令集，底层硬件的实现（微架构）也可以不同。 </p>
<p>最经典的计算机架构：冯-诺伊曼 架构：</p>
<p>Von Neumann Model: consisits of 5 parts:</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Von%20Neumann%20Model%20%26%20ISA/Von%20Neumann%20Model.png" alt="Von Neumann Model"></p>
<h4 id="1-1-Memory"><a href="#1-1-Memory" class="headerlink" title="1.1  Memory:"></a>1.1  Memory:</h4><ul>
<li><p>Word-addressable memory:</p>
</li>
<li><p>Byte-addressable memory: (eg. a byte represents pixel)</p>
</li>
<li><p>MAR &amp; MDR 寄存器组</p>
</li>
<li><p>Temporary storage: Registers(fast)</p>
<p>  Store intermediate results; </p>
<p>  Typically, a register contains 1 word.</p>
<p>  To Read</p>
<p>  Step 1: Load the MAR with the address</p>
<p>  Step 2: Data is placed in MDR</p>
<p>  To Write</p>
<p>  Step 1: Load the MAR with the address and the MDR with the data</p>
<p>  Step 2: Activate Write Enable signal</p>
</li>
</ul>
<h4 id="1-2-Processing-Unit"><a href="#1-2-Processing-Unit" class="headerlink" title="1.2 Processing Unit:"></a>1.2 Processing Unit:</h4><p>Arithmetic and logic unit (ALU)： ALU能处理的量化大小（size of quantity）通常被称为计算机的“字长“（word length），而量化的基本单位被称为一个字（word）。通常ALU周围会配置少量的存储器，以便它存放在最近生成的中间计算结果。通常是寄存器。</p>
<h4 id="1-3-input-amp-output"><a href="#1-3-input-amp-output" class="headerlink" title="1.3  input &amp; output"></a>1.3  input &amp; output</h4><p>They are called peripherals.</p>
<h4 id="1-4-Control-units"><a href="#1-4-Control-units" class="headerlink" title="1.4 Control units"></a>1.4 Control units</h4><p>It conducts the step-by-step process of executing (every instruction in) a program</p>
<p>组成：IR(instruction register) &amp;  PC(program counter) &amp; IP(instruction pointer)</p>
<h4 id="1-5-Two-Key-Properties-of-Von-Neumann-Model"><a href="#1-5-Two-Key-Properties-of-Von-Neumann-Model" class="headerlink" title="1.5 Two  Key Properties of Von Neumann Model:"></a>1.5 Two  Key Properties of Von Neumann Model:</h4><ul>
<li><p>Stored program:</p>
<ol>
<li>Instructions stored in a linear memory array</li>
<li>Memory is unified between instructions and data<br>The interpretation of a stored value depends on the control signals</li>
</ol>
</li>
<li><p>Sequential instruction processing:</p>
<ol>
<li>One instruction processed (fetched, executed, completed) at a time</li>
<li>Program counter (instruction pointer) identifies the current instruction</li>
<li>Program counter is advanced sequentially except for control transfer instructions</li>
</ol>
</li>
</ul>
<h3 id="2-instructions-set"><a href="#2-instructions-set" class="headerlink" title="2. instructions set:"></a>2. instructions set:</h3><p><strong>An instruction the most basic unit of computer processing</strong></p>
<ul>
<li>Instructions are words in the language of a computer</li>
<li>Instruction Set Architecture (ISA) is the vocabulary</li>
</ul>
<p>机器语言指：计算机能读懂的表达式（0s and 1s）</p>
<p>汇编语言指：人嫩读懂的表达式</p>
<h4 id="2-1-instructions-type"><a href="#2-1-instructions-type" class="headerlink" title="2.1 instructions type:"></a>2.1 instructions type:</h4><ul>
<li><p>Operate instructions</p>
<p>  Execute instructions in the ALU</p>
</li>
<li><p><strong>Data movement instructions</strong></p>
<p>  Read from or write to memory</p>
</li>
<li><p><strong>Control flow instructions</strong>q</p>
<p>  Change the sequence of execution</p>
</li>
</ul>
<h4 id="2-3-Instructions-Cycles-Typical-six-steps"><a href="#2-3-Instructions-Cycles-Typical-six-steps" class="headerlink" title="2.3 Instructions Cycles (Typical six steps)"></a>2.3 Instructions Cycles (Typical six steps)</h4><p>cycles are repreated once previous one is done.</p>
<ol>
<li><p><strong>FETCH</strong></p>
<p> The FETCH phase obtains the instruction from memory and loads it into the instruction register.</p>
<p> Completed description</p>
<p> Step 1: Load the MAR with the contents of the PC, and<br> simultaneously increment the PC</p>
<p> Step 2: Interrogate memory. This results the instruction to be<br> placed in the MDR</p>
<p> Step 3: Load the IR with the contents of the MDR</p>
</li>
<li><p><strong>DECODE</strong> </p>
<p> The DECODE phase identifies the instruction.</p>
</li>
<li><p><strong>EVALUATE ADDRESS</strong></p>
<p> The EVALUATE ADDRESS phase computes the address of the memory location that is needed to process the instruction. 计算基地址+偏移量</p>
</li>
<li><p><strong>FETCH OPERANDS</strong></p>
<p> The FETCH OPERANDS phase obtains the source operands needed to process the instruction.</p>
<p> 过程与读写memory的步骤一致。</p>
</li>
<li><p><strong>EXECUTE</strong></p>
<p> The EXECUTE phase executes the instruction.</p>
</li>
<li><p><strong>STORE RESULT</strong></p>
<p> The STORE RESULT phase writes to the designated destination</p>
</li>
</ol>
<p>Once STORE RESULT is completed, a new instruction cycle starts (with the FETCH phase)</p>
<h3 id="3-instruction-set-architcture-ISA"><a href="#3-instruction-set-architcture-ISA" class="headerlink" title="3 instruction set architcture (ISA)"></a>3 instruction set architcture (ISA)</h3><h4 id="3-0-Overview"><a href="#3-0-Overview" class="headerlink" title="3.0 Overview"></a>3.0 Overview</h4><p>An instruction refers to opeator and opearting values.</p>
<p>An instruction set refers to opcodes data types and addressing modes.</p>
<ol>
<li><p>Opcode操作码：可以分为运算，数据搬移和控制三种指令。</p>
</li>
<li><p>Data type数据类型：ISA是怎么理解这些表达信息。</p>
<p> LC-3只支持第二类补码整数；MIPS支持第二类补码整数，无符号整数，浮点数。</p>
<p> <strong>Note：data type tradeoffs</strong></p>
<p> A. Benefit of having higer-level data type: easy for programming</p>
<p> B. Disadvantage: more efforts at compiler design (semantic gap would be larger)</p>
</li>
<li><p>Addressing mode寻址模式：确定一个操作符指定数的位置。</p>
<p> 操作数的地址无非存在于三个位置：指令的某部分，寄存器中，内存中。</p>
<p> A.Immediate or literal (constant)</p>
<ol>
<li>The operand is in some bits of the instruction</li>
</ol>
<p> B. Register</p>
<ol start="2">
<li>The operand is in one of R0 to R7 registers</li>
</ol>
<p> C. Three of them are memory addressing modes</p>
<ol start="3">
<li>PC-relative</li>
<li>Indirect</li>
<li>Base+offset</li>
</ol>
</li>
</ol>
<p>In addition, MIPS has pseudo-direct addressing (for j and jal), but does not have indirect addressing.</p>
<h4 id="3-1-Opeartion-instructions-format-Case-of-MIPS"><a href="#3-1-Opeartion-instructions-format-Case-of-MIPS" class="headerlink" title="3.1 Opeartion instructions format:  Case of MIPS"></a>3.1 Opeartion instructions format:  Case of MIPS</h4><p>MIPS使用32位的指令，出于简洁的指令和复杂功能的折中，MIPS定义三种指令类型。更少的指令类型可以让可重复性（regularity）更高，因此硬件更加简单。（个人理解类似于：coding时，考虑到的branch更少，硬件资源更少）。各类指令的定义也是去指完成后译码的基础。</p>
<ol>
<li><p>R-type:  Register-type 使用到三个寄存器</p>
<p> 32位的指令分为六个部分：opcode操作符，rs源寄存器，rt第二级源寄存器，rd目标寄存器，shamt(移位)，funct（函数）每个部分都有大概5到6位bit。<br> <img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Von%20Neumann%20Model%20%26%20ISA/R-tyoe.png" alt="R-type"><br> 所有R-type的指令的opcode都是0。funct是32(100000)表示ADD，34表示sub。</p>
<p> 具体函数需要查询MIPS函数附录。</p>
<p> op: Operation of the instruction (opcode)<br> rs: First register source operand<br> rt: Second register source operand<br> rd: Register destination operand</p>
<p> shamt: Shift amount<br> funct: Function field (selects specific variant of opcode)</p>
</li>
<li><p>I-type:  Immdeiate-type： I-type指令使用到两个寄存器操作数和一个立即数操作数。</p>
<p> imm表示16位立即数。这个部分的操作只决定于opcode的内容。与R型不同，rs和imm总是作为源操作数，rt则是作为目标操作数（addi &amp; lw）或者源操作数（sw）。</p>
</li>
</ol>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Von%20Neumann%20Model%20%26%20ISA/I-type.png" alt="I-type"></p>
<p>几个例子：</p>
<p> <img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Von%20Neumann%20Model%20%26%20ISA/example.png" alt="examples"></p>
<p> Note：当16位的立即数加在一个寄存器 所对应的32为数据上如何操作：</p>
<p> 如果是正数，则高16位全部补0；如果是负数，则高16位全部补1。</p>
<pre><code>原理：sign  extension 符号为拓展，拓展最高位（MSB）不影响原来的数值。
</code></pre>
<ol start="3">
<li>J-type: jump-type：26位的地址操作数addr，6位opcode。</li>
</ol>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Von%20Neumann%20Model%20%26%20ISA/J-type.png" alt="J-type"></p>
<h4 id="3-2-ISA-instruction-set-architecture"><a href="#3-2-ISA-instruction-set-architecture" class="headerlink" title="3.2 ISA (instruction set architecture)"></a>3.2 ISA (instruction set architecture)</h4><p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Von%20Neumann%20Model%20%26%20ISA/ISA.png" alt="ISA"></p>
<p>ISA是硬件和软件的桥梁。trade-off 在硬件-软件的复杂度。</p>
<p>如果定义复杂的ISA（IS format中的opcodes长度变长，功能复杂）因此硬件设计的复杂度增加，软件设计会更加容易。</p>
<p>（ISA的另一种理解，编译器需要做什么：需要知道地址长度，需要知道寄存器组，操作数指令等）</p>
<h3 id="4-Memory-Map-amp-starting-a-program"><a href="#4-Memory-Map-amp-starting-a-program" class="headerlink" title="4 Memory Map &amp; starting a program"></a>4 Memory Map &amp; starting a program</h3><h4 id="4-1-memory-map"><a href="#4-1-memory-map" class="headerlink" title="4.1 memory map"></a>4.1 memory map</h4><p>MIPS架构把32位的地址空间分成 text segment, global data segment, dynamic data segment, and reserved segments.</p>
<ol>
<li>text segment: 存机器语言程序。MIPS可以存256MB的code。</li>
<li>global data segment：存全局变量。全局变量在程序启动时就被预先定义，MIPS中预留64KB的量用于存储全局变量。全局变量用 $gp作为全局指针来访问数据，指针地址会初始化在10008000的位置。</li>
<li>dynamic data segment：存堆栈内容。这个位置的内容在程序执行过程动态的分配和释放。这个存储容量最大的一个部分约2GB。这个部分用于存储寄存器的值，定义的局部变量。</li>
<li>reserved segment：被操作系统所使用，部分内容被用于中断和memory-map I/O。</li>
</ol>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Von%20Neumann%20Model%20%26%20ISA/memory%20map.png" alt="memory map"></p>
<h4 id="4-1-Translating-and-Starting-a-Program"><a href="#4-1-Translating-and-Starting-a-Program" class="headerlink" title="4.1 Translating and Starting a Program"></a>4.1 Translating and Starting a Program</h4><p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Von%20Neumann%20Model%20%26%20ISA/compiler%20and%20linker.png" alt="compiler and linker"></p>
]]></content>
      <categories>
        <category>Computer architecture</category>
      </categories>
      <tags>
        <tag>Computer architecture</tag>
      </tags>
  </entry>
  <entry>
    <title>Microarchitecture Part 3</title>
    <url>/2021/06/07/computer-architecture/microarchitecture-part-3/</url>
    <content><![CDATA[<p>Reference：</p>
<ol>
<li><em>Digital Design and Computer Architecture,</em> by David Harris, Sarah Harris</li>
<li><em>Introduction to Computing Systems</em>, by Yale N.Patt, Sanjay J. Patel</li>
</ol>
<h2 id="7-Pipeline-Processor-流水线处理器"><a href="#7-Pipeline-Processor-流水线处理器" class="headerlink" title="7. Pipeline Processor 流水线处理器"></a>7. Pipeline Processor 流水线处理器</h2><p>流水线处理器可以通过分割单周期处理成五个部分。因此最高可以有五条指令一起执行。流水线可以有效地提高吞吐量。</p>
<p>We design a pipelined processor by subdividing the single-cycle processor into five pipeline stages. Thus, five instructions can execute simultaneously, one in each stage.</p>
<p>流水线从时间的角度充分利用了硬件资源。<br><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%203/1.png" alt="流水线时间角度上硬件资源"></p>
<h3 id="7-1-Datapath-数据通路"><a href="#7-1-Datapath-数据通路" class="headerlink" title="7.1 Datapath 数据通路"></a>7.1 Datapath 数据通路</h3><p>读写内存和寄存器组和使用ALU通常是处理的最大delay的部分。五级流水线的每一级都涵盖了一部分这些高延迟部分。具体得，我们可以分成取指IF，译码DE，运算EX，读写内存MEM，写回WB五个部分。</p>
<p>Reading and writing the memory and register file and using the ALU typically constitute the biggest delays in the processor. We choose five pipeline stages so that each stage involves exactly one of these slow steps. Specifically, we call the five stages Fetch(IF), Decode(DE), Execute(EX), Memory(MEM), and Writeback(WB).</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%203/2.png" alt="错误5-stage"></p>
<p>简单得增加几级reg在组合逻辑电路和读写存储单元之间会导致一些问题，上图便有一处错误！对于一些指令数据/地址需要提前到达，会有时序上的问题</p>
<p>One of the subtle but critical issues in pipelining is that all signals associated with a particular instruction must advance through the pipeline in unison</p>
<p>错误在于寄存器组的写逻辑上。寄存器在流水线中是在DE中读取数据，WB中回写数据。然而在回写的地址在DE准备好，而不是WB。</p>
<p>The error is in the register file write logic, The register file is peculiar because it is read in the Decode stage and written in the Writeback stage. And the correct address is already covered by other instructions when it comes to writeback stage.</p>
<p>这个错误可以简单通过下图修改，将正确的地址一起传递到WB再写回，因此这个地址和WB回写的数据是逻辑上同步的。</p>
<p>The WriteReg signal is now pipelined along through the Memory and Writeback stages, so it remains in sync with the rest of the instruction. WriteRegW and ResultW are fed back together to the register file in the Writeback stage.</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%203/3.png" alt="正确5-stage"></p>
<p>事实上，流水线的设计关键难点在于处理hazards，处理指令执行的顺序。这个部分会在下面单独讨论。</p>
<p>A central challenge in pipelined systems is handling hazards that occur when the results of one instruction are needed by a subsequent instruction before the former instruction has completed. This section would be discussed sepearately later.</p>
<h3 id="7-2-Pipelined-Control-流水线控制"><a href="#7-2-Pipelined-Control-流水线控制" class="headerlink" title="7.2 Pipelined Control 流水线控制"></a>7.2 Pipelined Control 流水线控制</h3><p>通过取指后的opcode和funct译码控制存储的使能信号和MUX的选通信号。<br><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%203/4.png" alt="正确5-stage"></p>
<h3 id="7-3-Hazard"><a href="#7-3-Hazard" class="headerlink" title="7.3 Hazard"></a>7.3 Hazard</h3><p>在流水线系统中，多个指令在时间上同时被执行。当一条指令的的执行依赖于另一条指令完成的结果，则hazard发生。</p>
<p>When one instruction is dependent on the results of another that has not yet completed, a hazard occurs.</p>
<p>RAW(Read after write) hazard：下图表示hazard发生流水线写入寄存器组，如果接下来的两条指令读取寄存器时</p>
<p>RAW(Read after write) hazard：The diagram shows that hazards may occur in this pipeline when an instruction writes a register and either of the two subsequent instructions read that register.<br><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%203/5.png" alt="hazard"></p>
<p>通常来说如果遇到RAW hazard 最直白的解决方法就是流水线停下来等到hazard解决。仔细观察上述指令，我们可以发现：Add在EX时候在ALU已经完成了计算，在MEM级不需要任何操作。空等了一个周期才WB。可以通过提前向前传递ALU的结果来提前WB，减少流水线放慢的效率。</p>
<p>On closer inspection, however, observe that the sum from the add instruction is computed by the ALU in cycle 3 and is not strictly needed by the and instruction until the ALU uses it in cycle 4. In principle, we should be able to forward the result from one instruction to the next to resolve the RAW hazard without slowing down the pipeline.</p>
<p>Hazards 可以分成data hazard 和 control hazard。data hazard 发生在指令尝试读取一个寄存器，但该寄存器还未被写回时。control hazard 发生在当跳转指令还没决定下一条该跳转到那一条指令时候，取指已经发生。</p>
<p>Hazards are classified as data hazards or control hazards. A data hazard occurs when an instruction tries to read a register that has not yet been written back by a previous instruction. A control hazard occurs when the decision of what instruction to fetch next has not been made by the time the fetch takes place.</p>
<p>A    Data Hazard</p>
<p>B)    Control Hazard</p>
<p>C)    Branch Hazard</p>
]]></content>
      <categories>
        <category>Computer architecture</category>
        <category>Microarchitecture</category>
      </categories>
      <tags>
        <tag>Computer architecture</tag>
        <tag>Microarchitecture</tag>
      </tags>
  </entry>
  <entry>
    <title>Microarchitecture Part 1</title>
    <url>/2021/06/07/computer-architecture/microarchitecture-part-1/</url>
    <content><![CDATA[<p>Reference：</p>
<ol>
<li><em>Digital Design and Computer Architecture,</em> by David Harris, Sarah Harris</li>
<li><em>Introduction to Computing Systems</em>, by Yale N.Patt, Sanjay J. Patel</li>
</ol>
<h3 id="1-架构状态和指令集"><a href="#1-架构状态和指令集" class="headerlink" title="1. 架构状态和指令集"></a>1. 架构状态和指令集</h3><p>一个计算机架构是由它的指令集(instruction set)和架构状态(architectural state：The architectural state is the part of the CPU which holds the state of a process. )。MIPS处理器的架构状态包含程序计数器和32个寄存器。指令集决定了微架构的硬件层面的复杂程度。</p>
<h3 id="2-设计流程"><a href="#2-设计流程" class="headerlink" title="2. 设计流程"></a>2. 设计流程</h3><p>微架构可以分成两个相互作用的部分：数据通路(datapath)和控制通路(controlpath)。数据通路包括了内存，寄存器，ALU和分路选择器。控制通路则通过分路选择器（MUX）进行寄存器的enable控制，memory的读写以控制数据通路。</p>
<p>设计的过程可以分成几个步骤：</p>
<p>Step 1: 思考需要的硬件需要包含多少状态（多少级）存储元件。</p>
<p>Step 2: 在两级状态单元之间插入组合逻辑电路以计算next state。</p>
<p>Step 3: 通常会将架构的memory拆成两部分，一部分存储指令，另一部分存储数据。</p>
<h4 id="2-1-Case-study：MIPS-Micropossessor"><a href="#2-1-Case-study：MIPS-Micropossessor" class="headerlink" title="2.1 Case study：MIPS Micropossessor"></a>2.1 Case study：MIPS Micropossessor</h4><p>存储元件：存储元件通常还需要reset信号。</p>
<p>Note：1. instruction mem模块无clk，说明只要地址A改变，RD就会在一个短暂的组合逻辑delay后读出新的指令。2. 其余三个存储元件都是在clk的节拍下进行数据刷新，从时序的角度（寄存器的要求），地址和数据需要在时钟上升沿来之前保持一个setup time，在时钟上升沿来之后保持一个holding time。</p>
<p>The state of the system is changed only at the clock edge. The address, data, and write enable must setup sometime before the clock edge and must remain stable until a hold time after the clock edge.</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%201/1.png" alt="components"></p>
<h3 id="3-MIPS-架构"><a href="#3-MIPS-架构" class="headerlink" title="3  MIPS 架构"></a>3  MIPS 架构</h3><p>我们接下来会讨论三种MIPS架构：单周期，多周期和流水线的架构。这三种结构的不同点在于状态存储单元的连接和非架构状态的数量不相同。</p>
<ol>
<li><p>单周期微处理器：处理整一个整理在一个周期。</p>
<p> 特点：控制单元简单，不需要任何的非架构状态。但微处理器的周期时间被最慢的指令所限制。</p>
</li>
<li><p>多周期微处理器：处理一条指令用一系列短周期。简单的指令相比于复杂的指令执行更少的周期。多周期的微处理器通过重复使用昂贵的硬件资源如加法器和内存，以减少硬件cost。（adder可能在多个周期以不同用途被调用，多周期微处理器通过添加几个非架构寄存器来保存中间结果）。</p>
<p> 多周期微处理器一次指处理一个指令，一个指令会花费多个时钟周期。</p>
</li>
<li><p>流水线微处理器：将流水线应用在单周期微处理器架构上。</p>
<p> 特点：可以同时处理多条指令，极大提高系统的吞吐量。流水线则对控制通路的要求更高，需要昂贵的额外的MUX和非架构流水线寄存器。</p>
</li>
</ol>
<h3 id="4-Perfomance-analysis"><a href="#4-Perfomance-analysis" class="headerlink" title="4 Perfomance analysis"></a>4 Perfomance analysis</h3><p>微处理器的性能用执行特点程序（或程序集）所以花费时间而定。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%201/2.png" alt="execution time"></p>
<ol>
<li>instructions: 取决与处理器架构和执行的程序的内容。某些架构下有复杂的指令因而在每个指令可以做更多的事情，但是有种复杂的处理器架构意味着在硬件上更加复杂，往往执行得更慢。（在此处默认执行同一套程序）</li>
<li>CPI：不同的微处理器架构有不同CPIs。CPI与处理器架构，存储器架构相关。存储器的架构会对CPI产生显著的影响。</li>
<li>Tc：处理器能运行的最高频率取决于关键路径上的delay和寄存器时序要求。事实上，由于工艺节点的进步，尽管微架构和逻辑不变处理器也能运行在更高的频率上。</li>
</ol>
]]></content>
      <categories>
        <category>Computer architecture</category>
        <category>Microarchitecture</category>
      </categories>
      <tags>
        <tag>Computer architecture</tag>
        <tag>Microarchitecture</tag>
      </tags>
  </entry>
  <entry>
    <title>Microarchitecture Part 2</title>
    <url>/2021/06/07/computer-architecture/microarchitecture-part-2/</url>
    <content><![CDATA[<p>Reference：</p>
<ol>
<li><em>Digital Design and Computer Architecture,</em> by David Harris, Sarah Harris</li>
<li><em>Introduction to Computing Systems</em>, by Yale N.Patt, Sanjay J. Patel</li>
</ol>
<h2 id="5-Singlecycle-Processor-单周期处理器"><a href="#5-Singlecycle-Processor-单周期处理器" class="headerlink" title="5. Singlecycle Processor 单周期处理器"></a>5. Singlecycle Processor 单周期处理器</h2><p>通过连接存储单元来建立组合逻辑电路的数据通路。控制通路（组合逻辑电路）可以决定控制信号。</p>
<p>Overview: We begin constructing the datapath by connecting the state elements with combinational logic that can execute the various instructions. Control signals determine which specific instruction is carried out by the datapath at any given time.</p>
<h3 id="5-1-Datapath-数据通路"><a href="#5-1-Datapath-数据通路" class="headerlink" title="5.1 Datapath 数据通路"></a>5.1 Datapath 数据通路</h3><h4 id="5-1-1-Step-1"><a href="#5-1-1-Step-1" class="headerlink" title="5.1.1 Step 1"></a>5.1.1 Step 1</h4><p>读指令：PC (Program counter) 寄存器包含需要处理的指令地址。</p>
<p>The program counter (PC) register contains the address of the instruction to execute</p>
<p>（灰色表示先前讨论过的state elements，黑色表示数据通路）</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/1.png" alt="PC"></p>
<p>处理器的具体行为取决于具体的取出的指令，我们先考虑lw指令。</p>
<p>The processor’s actions depend on the specific instruction that was fetched. First we will work out the datapath connections for the lw instruction.</p>
<h4 id="5-1-2-Step-2"><a href="#5-1-2-Step-2" class="headerlink" title="5.1.2 Step 2"></a>5.1.2 Step 2</h4><p>对于lw指令，这一步需要做的是读base address 和 offset address。base地址对应指令中rs的部分，即 Instr25:21的部分。offset对应Instr15:0。</p>
<p>For a lw instruction, the next step is to read the source register containing the base address &amp; offset address. This register is specified in the rs field of the instruction, Instr25:21. The offset is stored in the immediate field of the instruction, Instr15:0.</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/2.png" alt="sign拓展"></p>
<p>由于十六位的地址可能是正数或者负数，必须要通过符号拓展成32位。</p>
<p>Because the 16-bit immedi- ate might be either positive or negative, it must be sign-extended to 32 bits</p>
<p>符号位拓展就是简单得将MSB（符号位）在高位复制拓展。</p>
<p>sign extension simply copies the sign bit (most significant bit) of a short input into all of the upper bits of the longer output.</p>
<h4 id="5-1-3-Step-3"><a href="#5-1-3-Step-3" class="headerlink" title="5.1.3 Step 3"></a>5.1.3 Step 3</h4><p>-Combinational calculation 组合逻辑计算</p>
<p>处理器需要将基地址（从寄存器中取）和偏移地址（拓展后）相加。两者通过一个三位ALU控制信号的控制下相加，产生ALUresult和zero信号，Zero 来表示结果是否为0。ALU结果送入数据存储器作为load指令的最终地址。</p>
<p>The processor must add the base address to the offset to find the address to read from memory. The 3-bit <em>ALUControl</em> signal specifies the operation. The ALU generates a 32-bit <em>ALUResult</em> and a <em>Zero</em> flag, that indicates whether <em>ALUResult</em> is 0. ALUResult is sent to the data memory as the address for the load instruction</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/3.png" alt="组合逻辑电路"></p>
<h4 id="5-1-4-Step-4"><a href="#5-1-4-Step-4" class="headerlink" title="5.1.4 Step 4"></a>5.1.4 Step 4</h4><ul>
<li>Mem reading / Mem 读取</li>
</ul>
<p>ALU的结果会作为Data memory的地址，经过一个时钟节拍后数据输出到 ReadData 总线写入目标寄存器中。具体目标寄存器对应地址在指令的rt部分即 Instr20:16的部分。黑线表示的是地址/数据。</p>
<p>The data is read from the data memory onto the ReadData bus, then written back to the destination register in the register file at the end of the cycle. The destination register for the lw instruction is specified in the rt field, Instr20:16.</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/4.png" alt="Mem读取"></p>
<h4 id="5-1-5-Step-5"><a href="#5-1-5-Step-5" class="headerlink" title="5.1.5 Step 5"></a>5.1.5 Step 5</h4><ul>
<li>Write Back 写回</li>
</ul>
<p>RegWrite连接在使能信号，数据和地址和使能信号准备好后，在下一个周期CLK上升沿时候写入register中。上图蓝色部分。</p>
<p>RegWrite is connected to the port 3 write enable input, WE3.The write takes place on the rising edge of the clock at the end of the cycle.</p>
<p>-Determine address of next instruction for PC //取下一条指令的PC加法</p>
<p>Instructions mem是byte accessable。MIPS的32位指令包含4个byte。因而取下一个指令时候需要将PC+。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/5.png" alt="PC加法"></p>
<p>-Next, let us extend the datapath to also handle the sw instruction.接下来我们focus在sw(store word)指令的数据通路</p>
<p>sw也是需要基地址+偏移来确定mem的地址。不同点在于sw是写入mem而不是读取mem。因而在ALU计算出mem地址后，写入mem的data也需要准备好。因而在取基地址时候，也同时完成了从寄存器取数据。寄存器对应的地址在Instr20:16。使能信号为MemWrite。</p>
<p>the sw instruction reads a base address from port 1 of the register and sign-extends an immediate. The ALU adds the base address to the immediate to find the memory address. All of these func- tions are already supported by the datapath. The register is specified in the rt field, Instr20:16.  Enable signal is MemWrite.</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/6.png" alt="地址写入"></p>
<p>-Next, consider extending the datapath to handle the R-type instructions 接下来我们考虑拓展数据通路到能处理R型指令。</p>
<p>加，减，或，比较。这些指令都是会用到从寄存器组中取数据并且在ALU中计算最后写回到寄存器组中。不同在于进行的是不同ALU操作。因此只需要添加不同的ALU硬件资源，使用不同ALU控制信号。</p>
<p>Add, sub, and, or, and slt. All of these instructions read two registers from the register file, perform some ALU operation on them, and write the result back to a third register file. They differ only in the specific ALU operation. Hence, they can all be handled with the same hardware, using different ALUControl signals.</p>
<p>增加MUX作为input的选择可以有效增加数据通路的处理能力。</p>
<p>This principle of enhancing the datapath’s capabilities by adding a multiplexer to choose inputs from several possibilities is extremely useful</p>
<p>如下，增加三个MUX来区分是lw&amp;sw还是R-type指令。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/7.png" alt="MUX&amp;WB"></p>
<p>branch 跳转指令</p>
<p>核心：增加一个MUX做选择，MUX的输入为正常变化的PC和branch后的PC，ALU返回是否需要跳转的选择信号。<br><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/8.png" alt="地址偏移量相加获得新地址"></p>
<h3 id="5-2-Control-path-控制通路"><a href="#5-2-Control-path-控制通路" class="headerlink" title="5.2 Control path 控制通路"></a>5.2 Control path 控制通路</h3><p>控制（译码）部分需要在取指完成之后，对指令opcode和funct（R-type的指令的opcode为0）进行译码以决定后面的数据如何执行。各个存储元件的使能信号，MUX的选通信号都要在译码控制单元的控制下执行。ALU使能的宽度（图中是三位）如果需要执行的指令集越多，ALU使能选通信号会更加复杂。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/9.png" alt="控制通路"></p>
<p>对于每一个指令，控制信号的真值表可以列出：</p>
<p>由于sw，beg不需要写回因而选通信号X表示dont care，方便组合逻辑电路的设计，使用*可以节省组合逻辑的面积和规模。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Computer%20architecture/Microarchitecture%20Part%202/10.png" alt="控制信号真值表"></p>
<h3 id="5-3-Performance-evaluation-性能的考量"><a href="#5-3-Performance-evaluation-性能的考量" class="headerlink" title="5.3 Performance evaluation // 性能的考量"></a>5.3 Performance evaluation // 性能的考量</h3><p>一个执行周期只执行一个周期，因此CPI=1。关键路径需要考虑lw load word取指到写回整个流程。</p>
<p>Each instruction in the single-cycle processor takes one clock cycle, so the CPI is 1. lw instruction provides the critical delay for accessing to the ALU, memory, and register file which are substantially slower than other operations.</p>
<h3 id="5-4-Comments"><a href="#5-4-Comments" class="headerlink" title="5.4 Comments"></a>5.4 Comments</h3><p>单周期微控制器有着三个主要的缺点：</p>
<p>The single-cycle processor has three primary weaknesses</p>
<ol>
<li><p>它要求的一个周期以维持最慢的一条指令lw而其他的质量都比它快。</p>
<p> First, it requires a clock cycle long enough to support the slowest instruction (lw), even though most instructions are faster.</p>
</li>
<li><p>过程中用到了三个加法器：ALU中和PC中两个，加法器在面积上昂贵，尤其是对于高速加法器。</p>
<p> Second, it requires three adders (one in the ALU and two for the PC logic); adders are relatively expensive circuits, especially if they must be fast.</p>
</li>
<li><p>它将指令存储器和数据存储器分离开。</p>
<p> Third, it has sepa- rate instruction and data memories, which may not be realistic. Most computers have a single large memory that holds both instructions and data and that can be read and written.</p>
</li>
</ol>
<h2 id="6-Multicycle-Processor-多周期微处理器"><a href="#6-Multicycle-Processor-多周期微处理器" class="headerlink" title="6. Multicycle Processor 多周期微处理器"></a>6. Multicycle Processor 多周期微处理器</h2><p>多周期处理解决上述的问题通过把指令拆成几个步骤。不同的指令有不同数量的步骤，复杂的指令步骤更多，因而需要更多时间完成。</p>
<p>The multicycle processor addresses these weaknesses by breaking an instruction into multiple shorter steps. Different instructions use different numbers of steps, so simpler instructions can complete faster than more complex ones.</p>
]]></content>
      <categories>
        <category>Computer architecture</category>
        <category>Microarchitecture</category>
      </categories>
      <tags>
        <tag>Computer architecture</tag>
        <tag>Microarchitecture</tag>
      </tags>
  </entry>
  <entry>
    <title>Clock Domain Crossing (CDC) Part 3</title>
    <url>/2021/05/29/cdc/cdc-3/</url>
    <content><![CDATA[<p>Check</p>
]]></content>
      <categories>
        <category>VLSI</category>
        <category>CDC</category>
      </categories>
      <tags>
        <tag>VLSI</tag>
        <tag>CDC</tag>
      </tags>
  </entry>
  <entry>
    <title>Clock Domain Crossing (CDC) Part 2</title>
    <url>/2021/05/29/cdc/cdc-2/</url>
    <content><![CDATA[<p>Reference：<br>《Clock Domain Crossing (CDC) Design &amp; Verification Techniques Using SystemVerilog》    -    Clifford E. Cummings</p>
<h3 id="2-4-Synchronizing-signals-requirements"><a href="#2-4-Synchronizing-signals-requirements" class="headerlink" title="2.4 Synchronizing signals requirements:"></a>2.4 Synchronizing signals requirements:</h3><h4 id="2-4-1-Requirment-for-sending-signals"><a href="#2-4-1-Requirment-for-sending-signals" class="headerlink" title="2.4.1 Requirment for sending signals"></a>2.4.1 Requirment for sending signals</h4><p>在发射时钟域&amp;接受时钟域，发送信号需要被registered。</p>
<p>对同步过程很容易误解成，只需要接受时钟域同步即可。但对于发送时钟域，异步信号是需要提前存在register中，即发送域寄存器和接受域寄存器之间不再有组合逻辑电路。若有组合逻辑电路：接受域的输入信号adat会由于组合逻辑电路不同输入变化带来不同情况的延迟变化，逻辑值不同等情况，这增加潜在毛刺（或是震荡信号）的可能性，也增加了亚稳态的可能。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/1.png" alt="without registered"></p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/2.png" alt="with registered"></p>
<h4 id="2-4-2-requirement-for-reliability-of-signals"><a href="#2-4-2-requirement-for-reliability-of-signals" class="headerlink" title="2.4.2 requirement for reliability of signals"></a>2.4.2 requirement for reliability of signals</h4><p>对信号的可靠性的要求。用更快的时钟采样慢信号（通常是1.5倍以上相较于慢信号），满信号会被采样一次或者多次，通常来说同步慢信号不会产生很多问题。但慢时钟采快信号会带来问题。</p>
<p>The “three edge” requirement：”input data values must be stable for three destination clock edges” 输入数据值需要在三个目标时钟沿保持稳定，即1.5个时钟周期。</p>
<p>Problem A: Passing a fast CDC pulse</p>
<p>当CDC信号只有一个快时钟周期的宽度，那么CDC信号可能在两个慢时钟的上升沿之间变化，因而接受时钟域并没有采集到信号变化。<br><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/3.png" alt="传递一个高速CDC脉冲"></p>
<p>Problem B: Sampling a long CDC pulse - but not long enough</p>
<p>当CDC信号的宽度大概略大于一个慢时钟周期的宽度，那么CDC信号在绝大多数情况下能顺利通过。但是在下图非常罕见的情况，adat恰好横跨一个慢周期的上升沿，那么有可能违反第一个寄存器的setup time要求和第二个寄存器的hold time要求，输出为亚稳态。<br><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/4.png" alt="采样一个不够长的CDC脉冲"></p>
<p>当不允许采样过程中丢失采样点，通常来说有两种方法来解决：</p>
<ol>
<li>开环控制：用同步器对信号进行采样：</li>
</ol>
<p>保证CDC信号大概在采样时钟周期地1.5倍左右，如此信号在一个周期中会被至少采样一次。</p>
<p>优点：开环地控制信号长度，最快的发送方式，不需要发送信号返回的acknowlegment。</p>
<p>缺点：当参数变化时候，工程师可能很难在发现这个错误。这个问题可以通过SV的断言来判断信号是否满足了3edge要求。<br>This problem can be minimized by adding a SystemVerilog Assertion to the model to detect if the input pulse ever fails to exceed the “three edges” design requirement.</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/5.png" alt="开环控制"></p>
<p>闭环控制：信号穿过CDC后返回一个acknowledgement反馈信号，自动延长快时钟域的信号<br>在发射时钟域添加一个使能信号。当接受时钟域接受到信号后，通过一个发射时钟域的两级同步器产生acknowledgement信号，数据再从adat进入，开始传入下一个数据。</p>
<p>缺点：整个过程延迟过长（两级同步器）</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/6.png" alt="闭环控制"></p>
<h2 id="3-Multiple-signals-between-clock-domains"><a href="#3-Multiple-signals-between-clock-domains" class="headerlink" title="3. Multiple signals between clock domains"></a>3. Multiple signals between clock domains</h2><p>当传输多位信号时，简单的同步器并不能保证数据的安全传输。多位信号的传输的问题在于信号在同步过程中，数据变化的偏移（skew）也可能被不同上升沿采样到。</p>
<p>为了应对多位CDC偏移采样的情况，主要有以下几种解决方案：</p>
<ul>
<li>尽可能让多位的CDC信号合成单bitCDC信号</li>
<li>Multi-cycle path formulation. 使用同步信号来保证CDC信号能通过</li>
<li>使用Gray code</li>
</ul>
<h3 id="3-1-控制信号多比特的同步"><a href="#3-1-控制信号多比特的同步" class="headerlink" title="3.1 控制信号多比特的同步"></a>3.1 控制信号多比特的同步</h3><h4 id="Problem-1：多个控制信号之间传输偏移"><a href="#Problem-1：多个控制信号之间传输偏移" class="headerlink" title="Problem 1：多个控制信号之间传输偏移"></a>Problem 1：多个控制信号之间传输偏移</h4><p>例如下面例子，当load信号和en信号同时在接收时钟域拉高，aq_load 和 aq_en才能同时被传输，才能实现load的操作。因而控制信号的skew可以导致两个控制信号的传输不同步，今儿导致后续接收时钟域的控制信号不同步。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/7.png" alt="多个控制信号"></p>
<h4 id="Solution-1：合并"><a href="#Solution-1：合并" class="headerlink" title="Solution 1：合并"></a>Solution 1：合并</h4><p>将两个控制信号合并成一个，控制信号之间就不存在同步问题。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/8.png" alt="合并"></p>
<h4 id="Problem-2-多个控制信号之间存在时钟相位差"><a href="#Problem-2-多个控制信号之间存在时钟相位差" class="headerlink" title="Problem 2: 多个控制信号之间存在时钟相位差"></a>Problem 2: 多个控制信号之间存在时钟相位差</h4><p>如果两个控制信号本身存在一定的时钟相位差，以满足一些逻辑或者数据传输的时序要求，那么在传输过程中（或者说在接收时钟域中），可能控制信号未被采集到。因而导致数据通路出问题</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/9.png" alt="时钟相位差"></p>
<h4 id="Solution-2：在接受域内产生控制信号"><a href="#Solution-2：在接受域内产生控制信号" class="headerlink" title="Solution 2：在接受域内产生控制信号"></a>Solution 2：在接受域内产生控制信号</h4><p>改进方法：只传输一个信号，另一个信号在同步时钟域中产生。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/10.png" alt="接受域产生控制信号"></p>
<h3 id="3-2-数据信号多比特的同步"><a href="#3-2-数据信号多比特的同步" class="headerlink" title="3.2 数据信号多比特的同步"></a>3.2 数据信号多比特的同步</h3><p>数据多位数据的传输对位间偏移敏感。下面例子展示了编码信号传播到接收时钟域，若偏移存在，可能导致接受时钟域产生完全错误的结果。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_2/11.png" alt="接受域产生控制信号"></p>
<p>解决数据同步方法主要有两种 </p>
<ol>
<li>Multi-cycle path formulation 多周期路径规划    </li>
<li>FIFO</li>
</ol>
]]></content>
      <categories>
        <category>VLSI</category>
        <category>CDC</category>
      </categories>
      <tags>
        <tag>VLSI</tag>
        <tag>CDC</tag>
      </tags>
  </entry>
  <entry>
    <title>Clock Domain Crossing (CDC) Part 1</title>
    <url>/2021/05/29/cdc/cdc-1/</url>
    <content><![CDATA[<p>Reference：</p>
<ol>
<li><p>《The Study of Synchronizer Design in Asynchronous Clock Domain System》-蒲田</p>
</li>
<li><p>《Clock Domain Crossing (CDC) Design &amp; Verification Techniques Using SystemVerilog》-Clifford E. Cummings</p>
</li>
</ol>
<h3 id="1-Metastability"><a href="#1-Metastability" class="headerlink" title="1. Metastability:"></a>1. Metastability:</h3><p>亚稳态指信号在一段时间内不再稳定在0或者1，原因在于存储元件并非理想元件，对于寄存器信号需要在时钟边沿前后保持不变（setup&amp;holding约束），否则可能产生不稳定的输出。在多时钟域设计中，亚稳态不能被避免但有害效应可以被中和抵消。</p>
<h4 id="1-1-Synchronization-failure"><a href="#1-1-Synchronization-failure" class="headerlink" title="1.1 Synchronization failure"></a>1.1 Synchronization failure</h4><p>下图展示两级FF，但是两级的CLK不同步，第二级FF在第一级输出未达到稳定时进行了采样，产生synchronization failure. 如下图，采样信号无法在bclk的下一个上升沿保持稳定，亚稳态会被传递。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_1/1.png" alt="同步错误"></p>
<p>“When sampling a changing data signal with a clock … the order of the events determines the outcome. The smaller the time difference between the events, the longer it takes to determine which came first. When two events occur very close together, the decision process can take longer than the time allotted, and a synchronization failure occurs.”</p>
<h4 id="1-2-Consideration"><a href="#1-2-Consideration" class="headerlink" title="1.2 Consideration"></a>1.2 Consideration</h4><p>每一级的FF都要一个具体的setup time 和 hold time，即要求input的数据在clock 上升沿前保持一段时间（setup）和之后保持一段时间（hold）。对于一个具体的设计而言，这个时间窗口（亚稳态窗口）可以视为一个design parameter，当这个时间窗口输入数据发生变化，输出就可能产生亚稳态。</p>
<h4 id="1-3-MTBF-Mean-Time-Before-Failure"><a href="#1-3-MTBF-Mean-Time-Before-Failure" class="headerlink" title="1.3 MTBF (Mean Time Before Failure)"></a>1.3 MTBF (Mean Time Before Failure)</h4><p>对于大多数应用，尤其是跨时钟域计算MTBF（Mean Time Before Failure）非常重要。Failure指的是信号通过通过一个同步寄存器进入亚稳态，持续保持亚稳态直到被下一级寄存器采样。MTBF表示两个failure之间的时间（希望大到几天，几年）。</p>
<p>MTBF表示触发器采样失败的时间间隔。MTBF的计算公式如下：MTBF的数值越大越好；大MTBF表明潜在失效发生在更长的时间范围内；小的MTBF表明亚稳态更可能发生。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_1/2.png" alt="MTBF相关"></p>
<p>定量计算公式如下：<br><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_1/3.png" alt="MTBF定量计算公式"><br>其中：</p>
<ul>
<li>tr = 分辨时间（时钟沿开始）// resolution time (start from clk edge)</li>
<li>𝜏,𝑇0 = 触发器参数 // parameters releated to FF</li>
<li>𝑓 = 采样时钟频率 // sampling frequency</li>
<li>a = 异步事件触发频率 // synchronized events activated frequency</li>
</ul>
<p>对于一个典型的 0.25µm 工艺的 ASIC 库中的一个触发器，我们取如下的参数：tr = 2.3ns, τ = 0.31ns, T0 = 9.6as, f=100MHZ, a = 10MHZ, MTBF = <strong>2.01 days</strong></p>
<h4 id="1-4-Approaches-to-reduce-metastability"><a href="#1-4-Approaches-to-reduce-metastability" class="headerlink" title="1.4 Approaches to reduce metastability"></a>1.4 Approaches to reduce metastability</h4><p>从MTBF的角度，减少亚稳态的方法有以下几种</p>
<ol>
<li><p>使用同步器：也就是我们常用的2级或者多级FF打拍的方法;同步器后面会专门论述；</p>
</li>
<li><p>降低频率：如果能满足功能要求，那么降低频率能够减少亚稳态的产生;</p>
</li>
<li><p>避免变化过快或者过于频繁的信号进行跨时钟采样</p>
</li>
<li><p>采用更快的触发器：更快的触发器，也可以减少亚稳态的产生。</p>
</li>
</ol>
<h3 id="2-Synchronizers"><a href="#2-Synchronizers" class="headerlink" title="2. Synchronizers"></a>2. Synchronizers</h3><p>当信号跨时钟域时候，最容易忽视的一个问题是，这个信号需要每个时钟都被采样，不能漏掉每一个值吗？这是新手最容易忽视的一个问题。当考虑到信号穿过CDC边界时，</p>
<p>我们考虑两种情况：</p>
<ul>
<li>有一些信号不需要sample 可以miss </li>
</ul>
<p>// some signals are not required to be sampled and could be missed.</p>
<ul>
<li>每一个信号都需要被sample 并且跨CDC </li>
</ul>
<p>// every signals are required to be sampled.</p>
<p>在这两种情况下：CDC信号都需要某种形式的同步在接收时钟域内<br>In both of these scenarios, the CDC signals will require some form of <strong>synchronization</strong> into the receiving clock domain.</p>
<p>同步器：是采样一个异步时钟信号，并将其过渡成与一个在本地或者采样时钟的输出信号。“A synchronizer is a device that samples an asynchronous signal and outputs a version of the signal that has transitions synchronized to a local or sample clock”</p>
<h4 id="2-1-Two-flip-flop-synchronizer"><a href="#2-1-Two-flip-flop-synchronizer" class="headerlink" title="2.1 Two flip-flop synchronizer"></a>2.1 Two flip-flop synchronizer</h4><p>最简单和最常用的同步器，是两级FF同步器.</p>
<p>第一级FF采样一个异步信号，极端情况（采样一个变化信号）则第一级FF输出为亚稳态；保持一个时钟周期（亚稳态recover），信号被重新采样为有效的输出。</p>
<p>Note：双寄存器并不能消除亚稳态，它只是减少出现亚稳态的概率，减少到一个可以几乎忽略不计的程度。<br><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_1/4.png" alt="两级同步器"></p>
<p>在这个过程，需要保证的这个保持时间，否则会产生synchronization failure。 这个时间与输入信号的频率和同步FF的频率有关。这个时间为MTBF。</p>
<p>对于大多数同步应用，两级FF同步器已经足够移除所有亚稳态。</p>
<h4 id="2-3-Three-flip-flop-synchronizer"><a href="#2-3-Three-flip-flop-synchronizer" class="headerlink" title="2.3 Three flip-flop synchronizer"></a>2.3 Three flip-flop synchronizer</h4><p>对于一些极其高速的应用，MTBF在两级同步器之间太短。因此可以添加第三级FF以增加MTBF到一个满意的时间范围。<br><img src="https://github.com/XuLixing/blog_images/raw/main/CDC/CDC_1/5.png" alt="三级同步器"></p>
]]></content>
      <categories>
        <category>VLSI</category>
        <category>CDC</category>
      </categories>
      <tags>
        <tag>VLSI</tag>
        <tag>CDC</tag>
      </tags>
  </entry>
  <entry>
    <title>DFT 1. Fault_model &amp; Failure_mechanisms</title>
    <url>/2021/05/29/design-for-testability/dft-1-fault-type/</url>
    <content><![CDATA[<ol>
<li>Core concept: Stuck-at-fault (SAT)</li>
</ol>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/DFT/1.fault_model%20%26%20failure_mechanisoms/1.png" alt="fault sites"></p>
<p>Notes: </p>
<p><strong>Mutiple SAT:</strong><br><strong>Multiple stuck-at faults are usually not considered in practice because of two reasons</strong></p>
<p><strong>– The number of multiple stuck-at faults in a circuit with k lines is 3^k-1, which is too large a number even for circuits of moderate size</strong></p>
<p>– <strong>Tests for single stuck-at faults are known to cover a very high percentage (greater than 99.6%) of multiple stuck-at faults when the circuit is large and has several outputs</strong></p>
<ol start="2">
<li>Stuck-open fault model (SOpF)</li>
</ol>
<p>Testing: need a sequential test vectors (tesing the transient from connect to disconnect)</p>
<ol start="3">
<li>Stuck-on fault model (SOnF): might contribute a directed path from vdd to ground.</li>
</ol>
<p>Testing: Iddq test, test the current whether is surficiently large.</p>
<ol start="4">
<li><p>Geometrical Fault Model: Bridging Faults (BFs) , get shorted for example.</p>
</li>
<li><p>Pattern-sensitive fault: changed by neightbor values. (DRAM)</p>
</li>
<li><p>Coupling fault: Between Cells (Victim and Aggressor)</p>
</li>
<li><p>Delay fault model: slow to propagate a 1 to 0 for example.</p>
</li>
<li><p>Crosstalk defects: </p>
</li>
</ol>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/DFT/1.fault_model%20%26%20failure_mechanisoms/2.png" alt="Crosstalk defects"></p>
<p>source from: tow parasitc capacitance between two signal nets.</p>
]]></content>
      <categories>
        <category>VLSI</category>
        <category>CDC</category>
      </categories>
      <tags>
        <tag>VLSI</tag>
        <tag>CDC</tag>
      </tags>
  </entry>
  <entry>
    <title>Efficient FSM coding in verilog</title>
    <url>/2021/04/05/fsm-coding/notes-fsm-coding/</url>
    <content><![CDATA[<p>Learning Source:《The Fundamentals of Efficient Synthesizable Finite State Machine Design using NC-Verilog and BuildGates》</p>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract:"></a>Abstract:</h3><ol>
<li>Important techniques related to one and two always block styles to code FSMs with combinational outputs are given to show why using a two always block style is preferred. </li>
<li>An efficient Verilog-unique onehot FSM coding style is also shown. </li>
<li>Reasons and techniques for registering FSM outputs are also detailed.</li>
</ol>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction:"></a>1. Introduction:</h3><h4 id="Note-利用Always语句编写组合逻辑电路和时序逻辑电路。"><a href="#Note-利用Always语句编写组合逻辑电路和时序逻辑电路。" class="headerlink" title="Note: 利用Always语句编写组合逻辑电路和时序逻辑电路。"></a>Note: 利用Always语句编写组合逻辑电路和时序逻辑电路。</h4><ol>
<li><p>组合逻辑电路的always block编写严格（阻塞赋值），敏感列表内没有posedge or negedge这些verilog keyword！</p>
<blockquote>
<p>Combinational always blocks are always blocks that are used to code combinational logic functionality and are strictly coded using blocking assignments。</p>
</blockquote>
</li>
<li><p>时序电路always block（非阻塞赋值），有edge-based sensitivity list。</p>
</li>
</ol>
<h3 id="2-Mearly-and-moore-FSM"><a href="#2-Mearly-and-moore-FSM" class="headerlink" title="2. Mearly and moore FSM"></a>2. Mearly and moore FSM</h3><p><img src="https://github.com/XuLixing/blog_images/raw/main/Learning_Notes/FSM/images/1.%20FSM%E7%B1%BB%E5%9E%8B.png" alt="Figure 1.FSM_type"></p>
<h3 id="3-Binary-or-Onehot-Encoded"><a href="#3-Binary-or-Onehot-Encoded" class="headerlink" title="3. Binary or Onehot Encoded?"></a>3. Binary or Onehot Encoded?</h3><ul>
<li><p>Binary-encode FSM 需要的位宽（FF的数量）仅是需要状态的log2（#states）</p>
<p>  优点：使用触发器的个数较少，节省资源。<br>  缺点：状态跳转时可能有多个bit错误，引起毛刺，造成逻辑错误。</p>
</li>
<li><p>One-hot encode FSM 需要的位宽（FF的数量）为需要的状态的数量。</p>
<p>  缺点：增加了触发器个数，寄存器资源利用效率低。<br>  优点：但是方便译码，有效化简组合逻辑电路</p>
</li>
</ul>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Learning_Notes/FSM/images/2.%20code%20style.png" alt="Figure 2.编码方式"></p>
<p>Notes：</p>
<ol>
<li><p>FPGA推荐使用one-hot编码因为其内置有足够数量的FF，使用one-hot编码可以节省复杂的译码组合逻辑电路设计。</p>
<blockquote>
<p>FPGA vendors frequently recommend using a onehot state encoding style because flip-flops are plentiful in an FPGA and the combinational logic required to implement a onehot FSM design is typically smaller than most binary encoding styles.</p>
</blockquote>
</li>
<li><p>FPGA的性能与FPGA中组合逻辑电路的size的决定。实现同样的功能，onehot码的用到的组合逻辑电路面积更小，可以run faster。</p>
<blockquote>
<p>Since FPGA performance is typically related to the combinational logic size of the FPGA design, onehot FSMs typically run faster than a binary encoded FSM with larger combinational logic blocks</p>
</blockquote>
</li>
</ol>
<h3 id="4-FSM-Coding-Goals："><a href="#4-FSM-Coding-Goals：" class="headerlink" title="4. FSM Coding Goals："></a>4. FSM Coding Goals：</h3><ul>
<li>The FSM coding style should be easily modified to change state encodings and FSM styles.</li>
<li>The coding style should be compact.</li>
<li>The coding style should be easy to code and understand.</li>
<li>The coding style should facilitate debugging.</li>
<li>The coding style should yield efficient synthesis results.</li>
</ul>
<h3 id="5-Two-Always-Block-FSM-style-Good"><a href="#5-Two-Always-Block-FSM-style-Good" class="headerlink" title="5. Two Always Block FSM style (Good)"></a>5. Two Always Block FSM style (Good)</h3><h4 id="5-1-Exapmle-Code"><a href="#5-1-Exapmle-Code" class="headerlink" title="5.1 Exapmle_Code"></a>5.1 Exapmle_Code</h4><p>用两个always block编写，一个写时序逻辑，一个写组合逻辑。</p>
<p>Note：</p>
<ol>
<li>时序always block定义时序电路（状态转移），非阻塞赋值。</li>
<li>组合always block定义组合逻辑电路，敏感列表为输入，没有时钟clk和复位信号，使用阻塞赋值。</li>
</ol>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Learning_Notes/FSM/images/3.4states_FSM.png" alt="Figure 3.Four-states FSM"></p>
<p>Important notes:</p>
<ol>
<li><p>Parameter 定义state类型（binary还是onehot）和名称（state的名字）：方便修改，如果需要换coding style的话就只需要更改parameter的定义就行。</p>
</li>
<li><p>在输出赋值之后，再给state or next state赋值。</p>
<blockquote>
<p>Declarations are made for state and next (next state) after the parameter assignments.</p>
</blockquote>
</li>
<li><p>时序逻辑用非阻塞赋值。</p>
<blockquote>
<p>The sequential always block is coded using nonblocking assignments.</p>
</blockquote>
</li>
<li><p>组合逻辑电路的敏感列表有state，所有组合逻辑input变量。</p>
</li>
<li><p>组合逻辑电路always block中用阻塞赋值。</p>
</li>
<li><p><strong>The combinational always block has a default next state assignment at the top of the always block</strong></p>
</li>
<li><p>输出在case语句前被赋初值（default value）。优点在于：</p>
<p> A. case语句之后不需要再写default的情况，电路上消除了产生锁存器的可能。<br> B. 每一个case中只在输出变化赋新的值。从代码上，更容易观察到输出的变化，代码可读性增加。</p>
<blockquote>
<p>Default output assignments are made before coding the <strong>case</strong> statement (this eliminates latches and reduces the amount of code required to code the rest of the outputs in the <strong>case</strong> statement and highlights in the <strong>case</strong> statement exactly in which states the individual output(s) change)</p>
</blockquote>
</li>
<li><p>组合逻辑always block内的if-else 语句数量和 状态转移图STD的转移弧线数量一致。（输入的 !rst不算）</p>
<blockquote>
<p>The number of transition arcs between states in the FSM state diagram should equal the number of <strong>if</strong>-<strong>else</strong>-type statements in the combinational always block.</p>
</blockquote>
</li>
<li><p>方便查看，next的赋值都放在同一列。</p>
</li>
</ol>
<h4 id="5-2-Fear-of-transitions-to-erroneous-states"><a href="#5-2-Fear-of-transitions-to-erroneous-states" class="headerlink" title="5.2 Fear of transitions to erroneous states"></a>5.2 Fear of transitions to erroneous states</h4><p>一般来说，不会发生。</p>
<p>在一些极端情况下，系统要求更高的robertness：如alpha粒子，高能粒子等。系统的状态可能进入到一个错误状态！但是让state/next state寄存器回到想要的状态并不够！这是因为可能，剩下部分的硬件已经进入变化后的state的状态。</p>
<p>Possible bad situation：系统可能因此进入一个lockup状态，因为硬件正在等待一个不可能到来的状态转移信号。（如系统在启动后，由于高能粒子轰击，刚好回到启动state，但是外界不会再给启动的激励，因而系统会卡在此状态不动）</p>
<p>解决办法：需要一种设计，当state寄存器进入到错误状态时：不仅下一个时刻，state能自动回到正常状态，剩下的状态也会在下一个状态过渡时候reset！</p>
<h4 id="5-3-Making-default-next-equal-all-X’s-assignment"><a href="#5-3-Making-default-next-equal-all-X’s-assignment" class="headerlink" title="5.3 Making default next equal all X’s assignment"></a>5.3 Making default next equal all X’s assignment</h4><p>在组合逻辑always敏感列表后，直接对next进行赋初值X‘s，next会在之后的case中被赋初值。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Learning_Notes/FSM/images/3.4states_FSM.png" alt="Figure 4.Four-states FSM"></p>
<p>如果我们给全X给next，如果某一状态转移可能没有在case语句中被描述到，state的预综合仿真模型会产生一个未知的输出的状态。这是一个有效debug FSM设计的方法。X在综合工具里认为是don’t care. </p>
<blockquote>
<p>By making a default next state assignment of X’s, pre-synthesis simulation models will cause the state machine outputs to go unknown if not all state transitions have been explicitly assigned in the case statement. This is a useful technique to debug state machine designs, plus the X’s will be treated as “don’t cares” by the synthesis tool.</p>
</blockquote>
<p><strong>不理解的问题：如果组合逻辑过于复杂？？？？如pcpu</strong></p>
<h3 id="6-One-Always-Block-FSM-style-Avoid"><a href="#6-One-Always-Block-FSM-style-Avoid" class="headerlink" title="6 One Always Block FSM style (Avoid)"></a>6 One Always Block FSM style (Avoid)</h3><h3 id="7-Onehot-FSM-Coding-style-Good-style"><a href="#7-Onehot-FSM-Coding-style-Good-style" class="headerlink" title="7 Onehot FSM Coding style. (Good style)"></a>7 Onehot FSM Coding style. (Good style)</h3><p>Onehot 编码与二进制编码的核心在于parameter不再代表state encoding，而是用来表示state向量的index。case的语句的比较则简化成单个bit的比较。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Learning_Notes/FSM/images/4.%20onehot_coding.png" alt="Figure 5.Onehot FSM"></p>
<p>Onehot 编码与二进制编码的核心在于parameter不再代表state encoding，而是用来表示state向量的index。case的语句的比较则简化成单个bit的比较。</p>
<p>在case语句下，比较进入分支时，本身带有优先级（即从第一种情况到default），因而这本身综合器会综合一个组合逻辑的优先级编码器电路。由于onehot编码本身不存在优先级，每一个case在逻辑上是并行，这是作者唯一推荐使用full_case 和 parallel_case 语句（告诉仿真器 1. 已经穷尽了所有case，不要生成锁存器 2.消除优先级编码器电路）</p>
<p>This is the only coding style where I recommend using full_case and parallel_case statements. The parallel case statement tells the synthesis tool to not build a priority encoder even though in theory, more than one of the state bits could be set (as engineers, we know that this is a onehot FSM and that only one bit can be set so no priority encoder is required). The value of the full_case statement is still in question.</p>
<p>Note：多个输出onehot编码，优先编码器</p>
<blockquote>
<p><a href="http://www.cburch.com/logisim/docs/2.3.0/libs/plexers/priencod.html">http://www.cburch.com/logisim/docs/2.3.0/libs/plexers/priencod.html</a></p>
</blockquote>
<p>关于parallel_case和full_case的使用</p>
<blockquote>
<p><a href="https://blog.csdn.net/teenagerold/article/details/78022636?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-0&spm=1001.2101.3001.4242">https://blog.csdn.net/teenagerold/article/details/78022636?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-0&amp;spm=1001.2101.3001.4242</a></p>
</blockquote>
<blockquote>
<p><a href="https://blog.csdn.net/childbor/article/details/78633541?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-1&spm=1001.2101.3001.4242">https://blog.csdn.net/childbor/article/details/78633541?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-1&amp;spm=1001.2101.3001.4242</a></p>
</blockquote>
<h3 id="8-Registered-FSM-Output-Good-style"><a href="#8-Registered-FSM-Output-Good-style" class="headerlink" title="8 Registered FSM Output. (Good style)"></a>8 Registered FSM Output. (Good style)</h3><p>在输出级加一个register可以保证输出没有glitch，优化综合结果。</p>
<p>Registering the outputs of an FSM design insures that the outputs are <strong>glitch-free</strong> and frequently improves synthesis results by standardizing the output and input delay constraints of synthesized modules.</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Learning_Notes/FSM/images/5.registeredFSM.png" alt="Figure 6.Registered FSM"></p>
<h3 id="9-System-Verilog-Enhancement"><a href="#9-System-Verilog-Enhancement" class="headerlink" title="9 System Verilog Enhancement"></a>9 System Verilog Enhancement</h3>]]></content>
      <categories>
        <category>FSM_verilog</category>
      </categories>
      <tags>
        <tag>FSM</tag>
      </tags>
  </entry>
  <entry>
    <title>Verilog Ch1&amp;2</title>
    <url>/2021/04/02/verilog/verilog-ch1-2/</url>
    <content><![CDATA[<p>In this chapter, we would focus on fundamentals and core concepts of Verilog HDL. 在这一章中，主要介绍一些概念和Verlog HDL的基础知识。</p>
<h3 id="0-模块概念："><a href="#0-模块概念：" class="headerlink" title="0.模块概念："></a>0.模块概念：</h3><ul>
<li><p>软核 Soft core:<br>  一般指经过功能验证，可综合的Verilog HDL（VHDL）模型.</p>
</li>
<li><p>固核 Firm core:<br>  通知指在ASIC or FPGA 器件上，经过综合验证的电路网表文件。</p>
</li>
<li><p>硬核 Hard core:<br>  在ASIC器件上，经过验证正确的的电路结构版图掩膜。</p>
</li>
</ul>
<h3 id="1-Verilog-HDL-基础"><a href="#1-Verilog-HDL-基础" class="headerlink" title="1.Verilog HDL 基础"></a>1.Verilog HDL 基础</h3><ul>
<li>数值状态</li>
</ul>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Learning_Notes/FSM/images/1.%20FSM%E7%B1%BB%E5%9E%8B.png" alt="Figure 1.Vaule_conditions"></p>
<ul>
<li>位制：二进制 b； 八进制: o；十进制：d；十六进制：h</li>
<li>整数表示 8‘b0000_0001。 位数‘位制‘数字</li>
</ul>
<h3 id="2-数据类型"><a href="#2-数据类型" class="headerlink" title="2. 数据类型"></a>2. 数据类型</h3><ul>
<li>分类：wire（tri三态门，tri0下拉电阻，tri1上拉电阻），reg，RAM</li>
<li>reg：对应硬件电路元件具有状态保持作用；触发器，锁存器</li>
<li>RAM：类似于二维数组的定义方式。 reg[7:0] mem1[255:0] //定义256个8位寄存器的mem。</li>
</ul>
<p>抽象数据类型：</p>
<ul>
<li>整型 integer，时间 time，实型 real ，参数型parameter.</li>
<li>integer index //定义32位有符号数</li>
<li>time a; // 定义两个64位的时间型变量。<br>主要用于对模拟时间的存储和计算处理，常与$time 一起使用</li>
<li>real stime; // 定义一个实数型数据（浮点型），常用于延迟时间的计算</li>
<li>parameter length=32, // 常量，在仿真之前就被复制，提高程序可读性。</li>
</ul>
<p>运算符：<br><img src="https://github.com/XuLixing/blog_images/raw/main/Learning_Notes/FSM/images/2.%20code%20style.png" alt="Figure 2.opeartors"></p>
<h4 id="Note"><a href="#Note" class="headerlink" title="Note:"></a><em>Note</em>:</h4><p>赋值语句下，结果的长度是由操作左端目标长度决定。取低N位，不够补0。</p>
<h3 id="3-条件运算符"><a href="#3-条件运算符" class="headerlink" title="3. 条件运算符"></a>3. 条件运算符</h3><p>example: (!sel)?in1:in2;</p>
<h3 id="4-连接和复制运算符"><a href="#4-连接和复制运算符" class="headerlink" title="4. 连接和复制运算符"></a>4. 连接和复制运算符</h3><p><img src="https://github.com/XuLixing/blog_images/raw/main/Verilog_Learning/Verilog_chapter_1%262/images_1%262/%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%A4%8D%E5%88%B6.png" alt="Figure 3.连接"></p>
<h3 id="5-模块的基本概念"><a href="#5-模块的基本概念" class="headerlink" title="5. 模块的基本概念"></a>5. 模块的基本概念</h3><p>Module是verilog HDL的基本单元</p>
<blockquote>
<p>组成：</p>
</blockquote>
<ul>
<li>开始：NAME module；- endmodule</li>
<li>端口定义：input output （模块引用具体）</li>
<li>数据类型定义： wire，reg，memory，parameter</li>
<li>逻辑功能描述：initial，always，assign，function，task</li>
</ul>
]]></content>
      <categories>
        <category>verilog</category>
      </categories>
      <tags>
        <tag>verilog</tag>
      </tags>
  </entry>
  <entry>
    <title>SV_1.1 Data Type</title>
    <url>/2021/04/02/system-verilog/sv-1.1-data-type/</url>
    <content><![CDATA[<p>Source from :</p>
<ol>
<li><p>《芯片验证漫游指南》- Page 108-111</p>
</li>
<li><p>《System Verilog验证》- Chapter 2</p>
</li>
</ol>
<h2 id="1-数据类型-内建数据类型："><a href="#1-数据类型-内建数据类型：" class="headerlink" title="1. 数据类型-内建数据类型："></a>1. 数据类型-内建数据类型：</h2><h3 id="1-1-logic-类型"><a href="#1-1-logic-类型" class="headerlink" title="1.1 logic 类型"></a>1.1 logic 类型</h3><p>SV中引入一个新的数据类型logic（还有net &amp; wire）</p>
<p>SV作为侧重于验证的语言，并不关切logic对应的逻辑应该被综合为寄存器还是线网，因为logic被使用的场景如果是验证环境，呢么它只会作为单纯的变量进行赋值操作，而这些变量也只属于软件环境构建。</p>
<p>原因：方便验证人员节省考虑是线网还是寄存器变量的时间和精力。</p>
<p>Note：</p>
<ul>
<li>logic 声明的变量可以被连续赋值，门单位和模块所驱动</li>
<li>使用net类型的地方均可以使用logic，但是要求logic不能有通过多个结构性的驱动（如双向总线建模），此时需要用net类型。</li>
</ul>
<p>Note:</p>
<ul>
<li><p>可以将所有类型（reg&amp;wire）都定义成logic，在多个驱动的地方会发生编译错误（编译器期待为wire类型）</p>
</li>
<li><p>logic 是四值逻辑（0，1，X，Z）</p>
</li>
</ul>
<h3 id="1-2-双状态数据类型"><a href="#1-2-双状态数据类型" class="headerlink" title="1.2 双状态数据类型"></a>1.2 双状态数据类型</h3><p>引入二状态数据类型（0 or 1）的原因：</p>
<ol>
<li>软硬scope区分：</li>
</ol>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/SV/1.1_data_type/1.png" alt="Figure 1.二值逻辑"></p>
<ol start="2">
<li>仿真器的内存使用减少，提高仿真器的精度。</li>
</ol>
<p>四值逻辑类型，二值逻辑类型变量划分</p>
<ul>
<li><p>四值：integer（32位）, logic, reg, net-type(wire)</p>
</li>
<li><p>二值：byte (类比C的char，8位), shortint（16位）, int（32位）, longint（64位）, bit (1 位)</p>
</li>
</ul>
<p>有符号类型，无符号类型变量划分</p>
<ul>
<li><p>有符号类型：byte，shortint，int，longint，integer</p>
</li>
<li><p>无符号类型：bit, logic, reg, net-type(wire &amp; tri)</p>
</li>
</ul>
<p>Case：</p>
<ol>
<li>不同数据类型的变量之间的赋值：</li>
</ol>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/SV/1.1_data_type/2.png"></p>
<p>ans：128，128，-128</p>
<ol start="2">
<li>不同位宽的数据转换 是 补0还是补1：</li>
</ol>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/SV/1.1_data_type/3.png"></p>
<p>ans：有符号数转换，先拓展了一位符号位。<code>h180。           无符号数转化，拓展补0。 </code>h080。</p>
<p>细节：在双状态变量连接DUT，尤其被测设计输出产生X or Z时候，这些值会被转换成0或者1，而测试代码可能永远检测不到X or Z。使用（$isunkown）操作符可以检查在任意位出现X还是Z时候，返回1。</p>
<p>数据转换：编码时一定要注意操作符左右两侧的符号类型是否一致，如果不一致，应该首先将其转换为同一类型再转换。</p>
<ul>
<li>静态转换<br>需要转换的表达式前加上单引号即可。编译时候检查。</li>
<li>动态转换</li>
</ul>
<p>$cast(tgt,src)。 仿真时候检查。</p>
<p>静态转化或者动态转换都需要操作符或者系统函数的介入，称为显式转换。</p>
<p>下面介绍隐式转换：</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/SV/1.1_data_type/4.png" alt="Figure 4.隐式转换"></p>
<p>四值逻辑转换成二值逻辑。（<strong>X只会变成0</strong>）：ans：111x，110</p>
<p>在操作不同变量时，除去变量的数值：需要考虑变量的以下性质：</p>
<ul>
<li>逻辑数值类型</li>
<li>符号类型</li>
<li>矢量位宽</li>
</ul>
<h2 id="2-定宽数组"><a href="#2-定宽数组" class="headerlink" title="2. 定宽数组"></a>2. 定宽数组</h2><h3 id="2-1-数组声明-amp-初始化："><a href="#2-1-数组声明-amp-初始化：" class="headerlink" title="2.1 数组声明&amp;初始化："></a>2.1 数组声明&amp;初始化：</h3><pre><code>int a [16] 
int a [0:15]
int array [8][4] ; // 创建一个8行4列的矩阵
array [7][3] = 1;  // 设置最后一个元素
</code></pre>
<p>Note：</p>
<ul>
<li><p>当你的程序试图读取一个超越定义范围的地址中读取数据，SV则会返回<strong>数组元素类型</strong>的缺省值。对于四状态类型的数组如logic，返回的是X；对于双状态类型例如int or bit 则返回0。</p>
</li>
<li><p>线网在没有驱动的时候输出是Z</p>
</li>
</ul>
<p>Note: </p>
<p>数组声明放在数组名字右边。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/SV/1.1_data_type/5.png" alt="Figure 5. 数组初始化"></p>
<p>Note: </p>
<ol>
<li><p><code>&#123;&#125; 赋值；Name = </code>{0, 1, 2, 3};</p>
</li>
<li><p>N {1} : 重复符号</p>
</li>
</ol>
<h3 id="2-2-存储空间考量（合并与非合并）"><a href="#2-2-存储空间考量（合并与非合并）" class="headerlink" title="2.2 存储空间考量（合并与非合并）"></a>2.2 存储空间考量（合并与非合并）</h3><p>SV仿真器在存放数组元素时候时，使用32bit（4 byte=1 word）的字边界。因此byte，shortint，int都是存在一个字。longint放在两个字。</p>
<ul>
<li><p>合并：</p>
<p>  bit [3][7:0] b_pack; // 维度声明放在了变量名左边，占用1个word</p>
</li>
<li><p>非合并：</p>
<p>  bit [7:0] b_unpack [3] // 如下，占用3个word.</p>
</li>
</ul>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/SV/1.1_data_type/6.png" alt="Figure 6.非合并space"></p>
<p>exercise</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/SV/1.1_data_type/7.png" alt="Figure 7."></p>
<p>ans: logic 是4值逻辑，软件上需要两位来存储。</p>
<p>第一种是合并存储：3<em>8</em>2/32=1.5  需要两个word</p>
<p>第二种是非合并存储：每一个word 足够存储一个数值，需要三个word。</p>
<h3 id="2-3-基本数组操作"><a href="#2-3-基本数组操作" class="headerlink" title="2.3 基本数组操作"></a>2.3 基本数组操作</h3><h4 id="2-3-1-for和foreach循环"><a href="#2-3-1-for和foreach循环" class="headerlink" title="2.3.1 for和foreach循环"></a>2.3.1 for和foreach循环</h4><pre><code>$size(Array Name); 返回数组的宽度
</code></pre>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/SV/1.1_data_type/8.png" alt="Figure 8. Foreach使用范例"></p>
<p>foreach 赋值多维数组的的语法，不是 [i][j]，而是[i,j]。</p>
<pre><code>foreach (md[i,j])
$display (&quot;md[%0d][%0d]=%0d&quot;, i , j, md[i][j]);
</code></pre>
<h4 id="2-3-2-赋值与比较"><a href="#2-3-2-赋值与比较" class="headerlink" title="2.3.2 赋值与比较"></a>2.3.2 赋值与比较</h4><p>赋值可以直接采用 = 传递</p>
<p>比较可以直接采用 == 进行两个数组的比较，不需要用for比较每个元素</p>
<p>还可以进行数组片段比较：</p>
<pre><code>$display(&quot;src[1:4] %s dst[1:4]&quot;, (src[1:4] == dst[1:4)? &quot;==&quot; : &quot;!=&quot;);
</code></pre>
<h3 id="2-4-合并数组与非合并数组"><a href="#2-4-合并数组与非合并数组" class="headerlink" title="2.4 合并数组与非合并数组"></a>2.4 合并数组与非合并数组</h3><p>合并数组的声明：必须是[msb:lsb] 不能是[size]</p>
<p>使用合并数组后，可以单独访问数组中的一部分。</p>
<p>关于合并数组的选择：</p>
<ul>
<li><p>需要以Byte或者word为单位进行对存储单位进行重复读写的需求</p>
</li>
<li><p>当需要等待数组的值的变化（敏感列表）必须使用合并数组。</p>
</li>
</ul>
<h2 id="3-动态数组"><a href="#3-动态数组" class="headerlink" title="3. 动态数组"></a>3. 动态数组</h2><p>数组的大小可以灵活调整宽度，可在仿真时灵活调节数组的大小即存储量。可以开辟新的存储空间。</p>
<p>Dyn数组的各种操作，赋值，拓展，删除。</p>
<p>int dyn[]</p>
<p>dyn= new [宽度]</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/SV/1.1_data_type/9.png" alt="Figure 9. 动态数组使用"></p>
<p>可以用一个常量数组给动态数组赋值。</p>
<p>int 的默认值是0， integer的默认值是1。</p>
<h2 id="4-队列"><a href="#4-队列" class="headerlink" title="4. 队列"></a>4. 队列</h2><p>结合了链表和数组；可以在任何一个地方添加，删除元素并且可以通过索引的方式实现对任一元素的访问。</p>
<p>优点：执行插入元素这种操作时，使用队列比使用动态数组带来的性能损失少（动态数组需要开辟新的存储空间，并复制原有的数组的数据）</p>
<p>队列的声明：</p>
<ol>
<li><p>Name[$]={0,1} // 不需要在前面加“ ` ”</p>
</li>
<li><p>name.insert(index, 内容) //在队列的某一位前插入一位或者一个队列</p>
</li>
<li><p>name.delete(index) //删除队列某一位数据</p>
</li>
</ol>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/SV/1.1_data_type/10.png" alt="Figure 10.队列使用"></p>
<pre><code> push_back() and pop_front() 的结合实现一个FIFO的用法
</code></pre>
<p>Note: </p>
<pre><code>q.size()         //查找q的队列长度, 
[$:2]: [0:2]         //使用$可以表示最大值或者最小值：
[2:$]: [2:最大值]
j =q[$]  //队列的最高位赋给j
</code></pre>
<h2 id="5-关联数组"><a href="#5-关联数组" class="headerlink" title="5. 关联数组"></a>5. 关联数组</h2><p>如果需要一个超大容量的数组（模拟存储器），若利用动态数组建立，一旦创建时就被固定下来，对于超大容量的数组则是浪费资源。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/SV/1.1_data_type/11.png" alt="Figure 11.关联数组使用"></p>
<h2 id="6-结构体"><a href="#6-结构体" class="headerlink" title="6. 结构体"></a>6. 结构体</h2><p>verilog中无数据结构，SV可以使用struct语句创建结构，跟C语言相似。</p>
]]></content>
      <categories>
        <category>SV</category>
      </categories>
      <tags>
        <tag>SV</tag>
      </tags>
  </entry>
  <entry>
    <title>Verilog Ch3</title>
    <url>/2021/04/02/verilog/verilog-ch3/</url>
    <content><![CDATA[<h3 id="3-1-数据流建模"><a href="#3-1-数据流建模" class="headerlink" title="3.1 数据流建模"></a>3.1 数据流建模</h3><h3 id="3-11-连续赋值语句"><a href="#3-11-连续赋值语句" class="headerlink" title="3.11 连续赋值语句"></a>3.11 连续赋值语句</h3><ul>
<li>标量，如wire a,b;</li>
<li>向量，如wire [3:0] a, b;</li>
</ul>
<p>Note：</p>
<blockquote>
<ol>
<li>Assign 类型 需要用 ‘=’</li>
<li>变量需要wire类型  </li>
<li>并行计算，没有顺序</li>
</ol>
</blockquote>
<h3 id="3-2-行为级建模"><a href="#3-2-行为级建模" class="headerlink" title="3.2 行为级建模"></a>3.2 行为级建模</h3><h3 id="3-2-1-过程语句"><a href="#3-2-1-过程语句" class="headerlink" title="3.2.1 过程语句"></a>3.2.1 过程语句</h3><p>A）initial 过程语句</p>
<p>initial 下顺序赋值，添加<code>[#100]</code>等表达式可以增加延迟。</p>
<p>格式：</p>
<pre><code>initial
    
    begin
    
    end
</code></pre>
<p>B）always 过程语句:</p>
<p>always @(敏感列表)</p>
<p>code example：</p>
<pre><code>always @()

    case()

    endcase
</code></pre>
<pre><code>always @( )

    begin

    end
</code></pre>
<p>Note:</p>
<blockquote>
<ol>
<li>在过程语句（initial 和 always）中，被赋值信号必须被定义为 reg 型。</li>
<li>采用过程对组合逻辑电路进行描述时：全部输入信号需要列入敏感列表。</li>
<li>采用过程对时序逻辑电路进行描述时：需要把时间信号和部分输入信号列入。</li>
</ol>
</blockquote>
<h3 id="3-2-2-语句块"><a href="#3-2-2-语句块" class="headerlink" title="3.2.2 语句块"></a>3.2.2 语句块</h3><p>A）begin-end：语句内部按照顺序执行，可以用于可综合电路程序和仿真测试程序。</p>
<p>B) fork-join: 语句内部按照按照并行方式，不可以用于可综合电路，只能用于仿真程序测试。</p>
<p>比较：<br><a href="https://github.com/XuLixing/blog_images/raw/main/Verilog_Learning/Verilog_chapter_3/images_3/1.%E6%AF%94%E8%BE%83.png">Figure 1.比较</a></p>
<p>###3.2.3 过程赋值语句</p>
<p><em>阻塞赋值语句和非阻塞赋值语句</em></p>
<ul>
<li>阻塞赋值语句“=” 有如下特点：<ol>
<li>串行语句块中，各条阻塞赋值语句将按照先后排列顺序一次执行。<br>并行语句块中，各条阻塞赋值语句同时执行，没有顺序</li>
<li>执行阻塞赋值语句的顺序是：先计算等号右端的表达式，然后立刻赋值给左边的变量，没有延时。</li>
</ol>
</li>
<li>非阻塞赋值语句“&lt;=” 有如下特点：<ol>
<li>串行语句块，各条非阻塞赋值语句的执行没有先后顺序之分。前面的语句不会影响后边语句的执行。各条语句并行执行。</li>
<li>执行非阻塞赋值语句的顺序是，先计算右端表达式的值，然后等到延时时间结束，再将计算的值付给左边的变量。</li>
</ol>
</li>
</ul>
<p>Note:<br>    需要掌握，阻塞和非阻塞电路对应verilog程序综合的电路的情况。<br><img src="https://github.com/XuLixing/blog_images/raw/main/Verilog_Learning/Verilog_chapter_3/images_3/2.%E9%98%BB%E5%A1%9E%E9%9D%9E%E9%98%BB%E5%A1%9E.png" alt="Figure 2.阻塞非阻塞"></p>
<p>###3.2.4 过程连续赋值语句<br>过程性连续赋值语句有两种类型：赋值，重新赋值( assign, deasign) 和 强制、释放（force，release）</p>
<h3 id="3-2-5-条件分支语句"><a href="#3-2-5-条件分支语句" class="headerlink" title="3.2.5 条件分支语句"></a>3.2.5 条件分支语句</h3><p>Verilog HDL的条件分支语句有两种，If条件语句和case条件分支语句</p>
<ol>
<li>if - else</li>
<li>case  条件分支。<br>容易实现多路分支选择控制的语句，更加直观和方便。</li>
</ol>
<pre><code>    case
    0 : 
    1 :
    ...: // 穷尽每一种情况
    default: 
    endcase
</code></pre>
<p><img src="https://github.com/XuLixing/blog_images/blob/main/Verilog_Learning/Verilog_chapter_3/images_3/3.%E6%95%B0%E7%A0%81%E7%AE%A1%E8%AF%91%E7%A0%81.png" alt="Figure 4.数码管译码"></p>
<p>Note : 使用case语句时，case应该包含所有的状态，如果没有包含全，则缺少项回产生锁存器！！！ 这是不允许的在同步时许电路设计中。</p>
<h3 id="3-2-6-循环语句"><a href="#3-2-6-循环语句" class="headerlink" title="3.2.6 循环语句"></a>3.2.6 循环语句</h3><ol>
<li><p>forever<br>永久循环。在永久循环内不包含任何条件表达式，只执行无限的循环，指导遇到系统任务¥finish为止。如果需要从forever循环汇总推出，则可以使用disable语句。<br><img src="https://github.com/XuLixing/blog_images/raw/main/Verilog_Learning/Verilog_chapter_3/images_3/3.forever.png" alt="Figure 4.forever"></p>
</li>
<li><p>repeat<br>所引导的循环语句执行固定次数的循环。<br><img src="https://github.com/XuLixing/blog_images/raw/main/Verilog_Learning/Verilog_chapter_3/images_3/5.repeat.png" alt="Figure 5.repeat"></p>
</li>
<li><p>while<br>仅有在while （） 括号内表达式为真才执行。<br><img src="https://github.com/XuLixing/blog_images/raw/main/Verilog_Learning/Verilog_chapter_3/images_3/6.while.png" alt="Figure 6.while"></p>
</li>
<li><p>for<br><img src="https://github.com/XuLixing/blog_images/raw/main/Verilog_Learning/Verilog_chapter_3/images_3/7.for.png" alt="Figure 7.for"></p>
</li>
</ol>
<h3 id="3-3-结构化建模"><a href="#3-3-结构化建模" class="headerlink" title="3.3 结构化建模"></a>3.3 结构化建模</h3><h4 id="3-3-1-模块级建模"><a href="#3-3-1-模块级建模" class="headerlink" title="3.3.1 模块级建模"></a>3.3.1 模块级建模</h4><ol>
<li><p>模块调用方式<br>在Verilog HDL中，模块可以被任何模块调用，这种调用实际上是将模块所描述的电路复制并连接。模块调用的基本语法格式是：<br>模块名 &lt;参数值列表&gt; 实例名 （端口名列表）：<br><img src="https://github.com/XuLixing/blog_images/raw/main/Verilog_Learning/Verilog_chapter_3/images_3/8.%E7%BB%93%E6%9E%84%E5%8C%96.png" alt="Figure 8.实例化"></p>
<p> Note：</p>
<p> A. 在同一个模块中当前模块被调用了几次，则需要用不同的实例名加以标明。</p>
<p> B. 当需要多次调用，可以采用 阵列调用的方式对模块进行调用。<br> （下面例子是对应位相与）</p>
</li>
</ol>
<p> <img src="https://github.com/XuLixing/blog_images/raw/main/Verilog_Learning/Verilog_chapter_3/images_3/9.%E7%BB%93%E6%9E%84%E5%8C%96.png" alt="Figure 9.多次实例化"></p>
<ol start="2">
<li>模块端口对应方式</li>
</ol>
<ul>
<li>端口位置对应方式：调用时，端口一定要严格按照端口定义顺序。</li>
<li>端口名对应方式：</li>
</ul>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/Verilog_Learning/Verilog_chapter_3/images_3/10.%20%E7%BB%93%E6%9E%84%E5%8C%96.png" alt="Figure 10.端口对应方式"></p>
<pre><code> .clk(clock), （）内是模块定义的变量，clk是调用模块的变量。
</code></pre>
<ul>
<li>不同端口位宽的匹配：从低位开始取。</li>
</ul>
<ol start="3">
<li> 模块参考值<br>有两种途径可以改变模块实例的参考值，分别是使用带有参数的模块实例语句修改参数值和使用定义参数语句（defparam）</li>
</ol>
<p>3.3.2 门级建模</p>
<p>3.3.3 开关级建模</p>
]]></content>
      <categories>
        <category>verilog</category>
      </categories>
      <tags>
        <tag>verilog</tag>
      </tags>
  </entry>
  <entry>
    <title>ASIC Design Flow 设计流程</title>
    <url>/2021/03/29/asic/asic-design-flow/</url>
    <content><![CDATA[<p>An ASIC (application-specific integrated circuit) is an IC customized for a particular use, rather than intended for general-purpose use</p>
<h2 id="0-ASIC-Overview"><a href="#0-ASIC-Overview" class="headerlink" title="0.ASIC Overview:"></a>0.ASIC Overview:</h2><h3 id="0-1-概况"><a href="#0-1-概况" class="headerlink" title="0.1 概况"></a>0.1 概况</h3><p>芯片结构基于基本单元，芯片内部网络网格化，等高单元在芯片内部整齐排列</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/VLSI_Design/1.VLSI_design_flow/images/1.VLSI_overviwe.png" alt="Figure 1.ASIC概况"></p>
<h3 id="0-2-标准单元库："><a href="#0-2-标准单元库：" class="headerlink" title="0.2 标准单元库："></a>0.2 标准单元库：</h3><ul>
<li>预先设计好的单元组成设计库</li>
<li>综合工具自动选取单元构建电路实现逻辑 ——— link2综合原理</li>
</ul>
<h3 id="0-3-ASIC的优势："><a href="#0-3-ASIC的优势：" class="headerlink" title="0.3 ASIC的优势："></a>0.3 ASIC的优势：</h3><p>相比于FPGA：平均而言，相同功能的电路， FPGA芯片所需的硅片面积是ASIC的35倍。 FPFA芯片的关键路径延时是ASIC的3.5倍。 FPGA芯片的动态功耗是ASIC的14倍。</p>
<h3 id="0-4-电路描述与设计过程："><a href="#0-4-电路描述与设计过程：" class="headerlink" title="0.4 电路描述与设计过程："></a>0.4 电路描述与设计过程：</h3><p><img src="https://github.com/XuLixing/blog_images/raw/main/VLSI_Design/1.VLSI_design_flow/images/2.%E7%94%B5%E8%B7%AF%E6%8F%8F%E8%BF%B0%E6%96%B9%E5%BC%8F.png" alt="Figure 2.不同层次描述"></p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/VLSI_Design/1.VLSI_design_flow/images/3.%E7%94%B5%E8%B7%AF%E6%8F%8F%E8%BF%B0%E6%8A%BD%E8%B1%A1.png" alt="Figure 3.前段/后端"></p>
<h2 id="1-ASIC设计流程"><a href="#1-ASIC设计流程" class="headerlink" title="1. ASIC设计流程"></a>1. ASIC设计流程</h2><h3 id="1-1-确定体系结构："><a href="#1-1-确定体系结构：" class="headerlink" title="1.1 确定体系结构："></a>1.1 确定体系结构：</h3><blockquote>
<p>寄存器组有多少组，数量多少</p>
</blockquote>
<blockquote>
<p>指令集：基本指令以及指令编码</p>
</blockquote>
<h3 id="1-2-体系微架构："><a href="#1-2-体系微架构：" class="headerlink" title="1.2 体系微架构："></a>1.2 体系微架构：</h3><blockquote>
<p>A. 多周期流水线结构框图</p>
</blockquote>
<blockquote>
<p>B. 控制信号逻辑，控制状态机，状态转移图</p>
</blockquote>
<h3 id="1-3-逻辑设计："><a href="#1-3-逻辑设计：" class="headerlink" title="1.3 逻辑设计："></a>1.3 逻辑设计：</h3><blockquote>
<p>A. 顶层接口：引脚数量，名称定义</p>
</blockquote>
<blockquote>
<p>B. 确定设计层次：控制通路和数据通路确定，电路组，标准单元库等等</p>
</blockquote>
<blockquote>
<p>C. 建立电路文档，包含行为级信息。使用硬件描述语言描述电路，并综合生成逻辑网表</p>
</blockquote>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/VLSI_Design/1.VLSI_design_flow/images/4.%20%E9%80%BB%E8%BE%91%E8%AE%BE%E8%AE%A1.png" alt="Figure 4.控制&amp;数据通路"></p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/VLSI_Design/1.VLSI_design_flow/images/5.%20%E8%AE%BE%E8%AE%A1%E5%B1%82%E6%AC%A1.png" alt="Figure 5.硬件的层次化描述"></p>
<h3 id="1-4-物理设计："><a href="#1-4-物理设计：" class="headerlink" title="1.4 物理设计："></a>1.4 物理设计：</h3><blockquote>
<p>A：导入标准单元库（等高）</p>
<p>B：Floorplan 平面规划</p>
<p>C：引脚布局</p>
</blockquote>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/VLSI_Design/1.VLSI_design_flow/images/6.%E7%89%A9%E7%90%86%E8%AE%BE%E8%AE%A1.png" alt="Figure 6.物理设计"></p>
<h3 id="1-5-设计验证："><a href="#1-5-设计验证：" class="headerlink" title="1.5 设计验证："></a>1.5 设计验证：</h3><blockquote>
<p>确保功能正确</p>
</blockquote>
<blockquote>
<p>确保时钟频率满足要求</p>
</blockquote>
<blockquote>
<p>确保功耗和面积满足要求</p>
</blockquote>
<blockquote>
<p>确保流片成功</p>
</blockquote>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/VLSI_Design/1.VLSI_design_flow/images/7.%E8%AE%BE%E8%AE%A1%E9%AA%8C%E8%AF%81.png" alt="Figure 7.设计过程"></p>
<h3 id="1-6-流片-（tape-out）"><a href="#1-6-流片-（tape-out）" class="headerlink" title="1.6 流片 （tape out）"></a>1.6 流片 （tape out）</h3><p><img src="https://github.com/XuLixing/blog_images/raw/main/VLSI_Design/1.VLSI_design_flow/images/11.%E6%B5%81%E7%89%87.png" alt="Figure 8.MPW 服务"></p>
<h3 id="1-7-封装（日月光）"><a href="#1-7-封装（日月光）" class="headerlink" title="1.7 封装（日月光）"></a>1.7 封装（日月光）</h3><p>封装有多种类型。引脚数量，封装材料，封装方式不同。</p>
<h3 id="1-9-测试（华天）"><a href="#1-9-测试（华天）" class="headerlink" title="1.9 测试（华天）"></a>1.9 测试（华天）</h3><h2 id="2-ASIC设计过程及其工具"><a href="#2-ASIC设计过程及其工具" class="headerlink" title="2 ASIC设计过程及其工具"></a>2 ASIC设计过程及其工具</h2><h3 id="2-1-数字ASIC设计可分为两个阶段，均包含设计与验证。"><a href="#2-1-数字ASIC设计可分为两个阶段，均包含设计与验证。" class="headerlink" title="2.1 数字ASIC设计可分为两个阶段，均包含设计与验证。"></a>2.1 数字ASIC设计可分为两个阶段，均包含设计与验证。</h3><p><img src="https://github.com/XuLixing/blog_images/raw/main/VLSI_Design/1.VLSI_design_flow/images/8.ASIC%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B.png" alt="Figure 9.ASIC粗略可分为两个阶段"></p>
<h3 id="2-2-基于Synosys平台各项工具及其功能："><a href="#2-2-基于Synosys平台各项工具及其功能：" class="headerlink" title="2.2 基于Synosys平台各项工具及其功能："></a>2.2 基于Synosys平台各项工具及其功能：</h3><p><img src="https://github.com/XuLixing/blog_images/raw/main/VLSI_Design/1.VLSI_design_flow/images/9.ASIC%E5%B7%A5%E5%85%B7.png" alt="Figure 10.ASIC设计工具"></p>
<p>设计过程中：RTL代码是通用代码，但是门级网表和版图必须是确定工艺的网表和版图。工艺对芯片的速度、面积和功耗有决定性的作用。</p>
<p><img src="https://github.com/XuLixing/blog_images/raw/main/VLSI_Design/1.VLSI_design_flow/images/10.%E5%B7%A5%E8%89%BA%E7%BD%91%E8%A1%A8%E5%92%8C%E7%89%88%E5%9B%BE.png" alt="Figure 11.逻辑/物理综合的原理"></p>
<p>————————————————————————</p>
<h2 id="3-Appendix"><a href="#3-Appendix" class="headerlink" title="3 Appendix"></a>3 Appendix</h2><p>Detailed Design Flow：(Based on Synopsys)</p>
<ol>
<li>将已经在 FPGA 上验证过的代码(Verilog)修改为不依赖于 FPGA 资源 的 RTL 代码。</li>
<li>使用 VCS 对 RTL 代码进行输入输出关系仿真，进行功能验证。</li>
<li>使用 Design Compiler(DC)对 RTL 代码进行逻辑综合，获得 DC 网<br>表。</li>
<li>使用 Formality 对 RTL 代码和 DC 网表进行形式验证，验证两者的结构 一致性。</li>
<li>使用 VCS 对 DC 网表进行输入输出关系仿真，对比 RTL 仿真的结果， 验证两者的功能一致性。</li>
<li>使用 IC Compiler(ICC)对 DC 网表进行物理综合，获得 ICC 网表和 版图。</li>
<li>使用 Calibre 对版图进行设计天线规则检查，规则检查(DRC)和原理 图版图一致性检查(LVS)。</li>
<li>使用 Formality 对 DC 网表和 ICC 网表进行形式验证，验证两者的结构 一致性。</li>
<li>使用 StarRC 对版图进行电容电阻参数提取，获得 RC 参数，进一步获 得各网线的延迟信息。此将此延迟信息并反标至 ICC 网表。</li>
<li>使用 PrimeTime 对反标后的 ICC 网表进行时序分析，并导出 sdf 延时文 件用于 VCS 后仿。</li>
<li>使用 VCS 对反标后的 ICC 网表进行输入输出关系仿真，对比 RTL 仿真 的结果，验证两者的功能一致性。</li>
<li>获得 GDSII 文档。</li>
</ol>
]]></content>
      <categories>
        <category>VLSI</category>
      </categories>
      <tags>
        <tag>VLSI</tag>
      </tags>
  </entry>
</search>
